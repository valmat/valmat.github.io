<!DOCTYPE html>
<html
  itemscope
  itemtype="http://schema.org/WebPage"
  lang="en"
  class="color-toggle-hidden"
  
>
  <head>
    <meta charset="UTF-8" />
<meta name="referrer" content="no-referrer" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="generator" content="Hugo 0.152.1">
  <meta name="robots" content="index, follow" />
  <meta name="description" content="Приводится алгоритм нахождения функций распределения в качестве решения задачи регрессии.
В общем виде задачу регрессии можно сформулировать как восстановление зависимости
$\phi: X \to L_1(\Omega)$,
сопоставляющей элементам некоторого фазового пространства $X$ случайную величину $\xi \in L_1(\Omega)$.
Классический подход к решению задачи регрессии состоит в нахождении среднего значения $E[\phi(x)]$ для каждого $x \in X$.
В статье предлагается простой алгоритм оценки распределений случайных величин $\phi(x) \in L_1(\Omega)$.
GitHub
Мотивация Описание подхода Постановка задачи Построение модели Ограничения Итоговый алгоритм Валидация Эксперименты Заключение Мотивация В анализе данных значительное место занимают два класса задач — задачи классификации и регрессии." />

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js" integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6" crossorigin="anonymous"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous"
  onload="renderMathInElement(document.body, {delimiters: [
  {left: '$$', right: '$$', display: true},
  {left: '$', right: '$', display: false}
]});"></script>



    <title>Получение распределений в задачах регрессии | Valmat&#39;s Personal Blog</title>

    
<link rel="icon" type="image/svg+xml" href="/favicon/favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
<link rel="manifest" href="/favicon/site.webmanifest">
<link rel="mask-icon" href="/favicon/safari-pinned-tab.svg" color="#efefef">
<meta name="msapplication-TileColor" content="#efefef">
<meta name="theme-color" content="#efefef">

    

    
  <meta
    property="og:title"
    content="Получение распределений в задачах регрессии"
  />
  <meta property="og:site_name" content="Valmat's Personal Blog" />
  <meta property="og:description" content="Приводится алгоритм нахождения функций распределения в качестве решения задачи регрессии.
В общем виде задачу регрессии можно сформулировать как восстановление зависимости
$\phi: X \to L_1(\Omega)$,
сопоставляющей элементам некоторого фазового пространства $X$ случайную величину $\xi \in L_1(\Omega)$.
Классический подход к решению задачи регрессии состоит в нахождении среднего значения $E[\phi(x)]$ для каждого $x \in X$.
В статье предлагается простой алгоритм оценки распределений случайных величин $\phi(x) \in L_1(\Omega)$.
GitHub
Мотивация Описание подхода Постановка задачи Построение модели Ограничения Итоговый алгоритм Валидация Эксперименты Заключение Мотивация В анализе данных значительное место занимают два класса задач — задачи классификации и регрессии." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://valmat.ru/posts/2022/09/regress-distr/" />

<meta property="article:section" content="Posts" />
    <meta
      property="article:published_time"
      content="2022-09-20T12:00:00+03:00"
    />
    <meta
      property="article:modified_time"
      content="2022-09-20T12:00:00+03:00"
    />


  <meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Получение распределений в задачах регрессии" />
  <meta name="twitter:description" content="Приводится алгоритм нахождения функций распределения в качестве решения задачи регрессии.
В общем виде задачу регрессии можно сформулировать как восстановление зависимости
$\phi: X \to L_1(\Omega)$,
сопоставляющей элементам некоторого фазового пространства $X$ случайную величину $\xi \in L_1(\Omega)$.
Классический подход к решению задачи регрессии состоит в нахождении среднего значения $E[\phi(x)]$ для каждого $x \in X$.
В статье предлагается простой алгоритм оценки распределений случайных величин $\phi(x) \in L_1(\Omega)$.
GitHub
Мотивация Описание подхода Постановка задачи Построение модели Ограничения Итоговый алгоритм Валидация Эксперименты Заключение Мотивация В анализе данных значительное место занимают два класса задач — задачи классификации и регрессии." />

<script type="application/ld+json">
  {
      "@context": "http://schema.org",
      "@type": "BlogPosting",
      "articleSection": "Posts",
      "name": "Получение распределений в задачах регрессии",
      "url" : "https://valmat.ru/posts/2022/09/regress-distr/",
      "headline": "Получение распределений в задачах регрессии",
      "description": "Приводится алгоритм нахождения функций распределения в качестве решения задачи регрессии.\nВ общем виде задачу регрессии можно сформулировать как восстановление зависимости\n$\\phi: X \\to L_1(\\Omega)$,\nсопоставляющей элементам некоторого фазового пространства $X$ случайную величину $\\xi \\in L_1(\\Omega)$.\nКлассический подход к решению задачи регрессии состоит в нахождении среднего значения $E[\\phi(x)]$ для каждого $x \\in X$.\nВ статье предлагается простой алгоритм оценки распределений случайных величин $\\phi(x) \\in L_1(\\Omega)$.\nGitHub\nМотивация Описание подхода Постановка задачи Построение модели Ограничения Итоговый алгоритм Валидация Эксперименты Заключение Мотивация В анализе данных значительное место занимают два класса задач — задачи классификации и регрессии.",
      "wordCount" : "1787",
      "inLanguage": "en",
      "isFamilyFriendly": "true",
      "mainEntityOfPage": {
          "@type": "WebPage",
          "@id": "https://valmat.ru/posts/2022/09/regress-distr/"
      },
      "keywords" : [ "AI" , "algo" ],
      "author" : [
      ],
      "copyrightHolder" : "Valmat\u0027s Personal Blog",
      "copyrightYear" : "2022",
      "dateCreated": "2022-09-20T12:00:00.00Z",
      "datePublished": "2022-09-20T12:00:00.00Z",
      "dateModified": "2022-09-20T12:00:00.00Z",
      "publisher":{
          "@type":"Organization",
          "name": "Valmat's Personal Blog",
          "url": "https://valmat.ru/",
          "logo": {
              "@type": "ImageObject",
              "url": "https://valmat.ru/brand.svg",
              "width":"32",
              "height":"32"
          }
      }
  }
  </script>


    
  <script src="/js/colortheme-c15a9bc4.bundle.min.js"></script>
<script src="/js/main-de0fc7bf.bundle.min.js"></script>

<link
  rel="preload"
  as="font"
  href="/fonts/Metropolis.woff2"
  type="font/woff2"
  crossorigin="anonymous"
/>
<link
  rel="preload"
  as="font"
  href="/fonts/LiberationSans.woff2"
  type="font/woff2"
  crossorigin="anonymous"
/>
<link
  rel="preload"
  as="font"
  href="/fonts/GeekblogIcons.woff2"
  type="font/woff2"
  crossorigin="anonymous"
/>

<link
  rel="preload"
  href="/main-d8f6de16.min.css"
  as="style"
/>
<link
  rel="stylesheet"
  href="/main-d8f6de16.min.css"
  media="all"
/>

<link
  rel="preload"
  href="/mobile-7fcdde51.min.css"
  as="style"
/>
<link
  rel="stylesheet"
  href="/mobile-7fcdde51.min.css"
  media="screen and (max-width: 45rem)"
/>

<link
  rel="preload"
  href="/print-cc34f864.min.css"
  as="style"
/>
<link
  rel="stylesheet"
  href="/print-cc34f864.min.css"
  media="print"
/>

<link
  rel="preload"
  href="/custom.css"
  as="style"
/>
<link
  rel="stylesheet"
  href="/custom.css"
  media="all"
/>
  <link href="https://valmat.ru/posts/2022/09/regress-distr/" rel="canonical" type="text/html" />
    <link href="https://valmat.ru/feed.xml" rel="alternate" type="application/atom+xml" title="Valmat's Personal Blog atom Feed" />

<!-- Made with Geekblog theme https://github.com/thegeeklab/hugo-geekblog -->

    

  </head>

  <body>
    
  <!-- geekblog include: /sprites/geekblog.svg -->
  <svg class="svg-sprite" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_arrow_back" xmlns="http://www.w3.org/2000/svg"><path d="M31.999 14.035v3.93H7.673l11.134 11.228L16 32 .001 16.001 16 .002l2.807 2.807L7.673 14.037h24.326z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_arrow_left" xmlns="http://www.w3.org/2000/svg"><path d="M7.954 17.965v5.988L.001 16l7.953-7.953v5.988H32v3.93H7.954z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_arrow_right" xmlns="http://www.w3.org/2000/svg"><path d="M24.046 14.035V8.047L31.999 16l-7.953 7.953v-5.988H0v-3.93h24.046z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_bitbucket" xmlns="http://www.w3.org/2000/svg"><path d="M15.905 13.355c.189 1.444-1.564 2.578-2.784 1.839-1.375-.602-1.375-2.784-.034-3.403 1.151-.705 2.818.223 2.818 1.564zm1.907-.361c-.309-2.44-3.076-4.056-5.328-3.042-1.426.636-2.389 2.148-2.32 3.747.086 2.097 2.08 3.815 4.176 3.626s3.729-2.234 3.472-4.331zm4.108-9.315c-.756-.997-2.045-1.169-3.179-1.358-3.214-.516-6.513-.533-9.727.034-1.066.172-2.269.361-2.939 1.323 1.1 1.031 2.664 1.186 4.073 1.358 2.544.327 5.156.344 7.699.017 1.426-.172 3.008-.309 4.073-1.375zm.979 17.788c-.481 1.684-.206 3.953-1.994 4.932-3.076 1.701-6.806 1.89-10.191 1.289-1.787-.327-3.884-.894-4.864-2.578-.43-1.65-.705-3.334-.98-5.018l.103-.275.309-.155c5.121 3.386 12.288 3.386 17.427 0 .808.241.206 1.22.189 1.805zM26.01 4.951c-.584 3.764-1.255 7.51-1.908 11.257-.189 1.1-1.255 1.719-2.148 2.183-3.214 1.615-6.96 1.89-10.483 1.512-2.389-.258-4.829-.894-6.771-2.389-.911-.705-.911-1.908-1.083-2.922-.602-3.523-1.289-7.046-1.719-10.604.206-1.547 1.942-2.217 3.231-2.698C6.848.654 8.686.362 10.508.19c3.884-.378 7.854-.241 11.618.859 1.341.395 2.784.945 3.695 2.097.412.533.275 1.203.189 1.805z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_bookmark" xmlns="http://www.w3.org/2000/svg"><path d="M20.357 5.856q1.157 0 2.043.851t.885 2.008v23.284l-10.212-4.357-10.144 4.357V8.715q0-1.157.885-2.008t2.042-.851h14.502zm5.787 18.859V5.856q0-1.157-.851-2.042t-2.008-.885H8.715q0-1.157.885-2.042t2.043-.885h14.502q1.157 0 2.043.885t.885 2.042v23.216z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_brightness_auto" xmlns="http://www.w3.org/2000/svg"><path d="M16.846 18.938h2.382L15.22 7.785h-2.44L8.772 18.938h2.382l.871-2.44h3.95zm7.087-9.062L27.999 14l-4.066 4.124v5.809h-5.809L14 27.999l-4.124-4.066H4.067v-5.809L.001 14l4.066-4.124V4.067h5.809L14 .001l4.124 4.066h5.809v5.809zm-11.385 4.937L14 10.282l1.452 4.531h-2.904z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_brightness_dark" xmlns="http://www.w3.org/2000/svg"><path d="M14 21.435q3.079 0 5.257-2.178T21.435 14t-2.178-5.257T14 6.565q-1.51 0-3.079.697 1.917.871 3.108 2.701T15.22 14t-1.191 4.037-3.108 2.701q1.568.697 3.079.697zm9.933-11.559L27.999 14l-4.066 4.124v5.809h-5.809L14 27.999l-4.124-4.066H4.067v-5.809L.001 14l4.066-4.124V4.067h5.809L14 .001l4.124 4.066h5.809v5.809z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_brightness_light" xmlns="http://www.w3.org/2000/svg"><path d="M14 21.435q3.079 0 5.257-2.178T21.435 14t-2.178-5.257T14 6.565 8.743 8.743 6.565 14t2.178 5.257T14 21.435zm9.933-3.311v5.809h-5.809L14 27.999l-4.124-4.066H4.067v-5.809L.001 14l4.066-4.124V4.067h5.809L14 .001l4.124 4.066h5.809v5.809L27.999 14z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_check" xmlns="http://www.w3.org/2000/svg"><path d="M8.885 20.197 25.759 3.323l2.24 2.24L8.885 24.677 0 15.792l2.24-2.24z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_check_circle_outline" xmlns="http://www.w3.org/2000/svg"><path d="M14 25.239q4.601 0 7.92-3.319T25.239 14 21.92 6.08 14 2.761 6.08 6.08 2.761 14t3.319 7.92T14 25.239zM14 0q5.784 0 9.892 4.108T28 14t-4.108 9.892T14 28t-9.892-4.108T0 14t4.108-9.892T14 0zm6.441 7.822 1.972 1.972-11.239 11.239L4.207 14l1.972-1.972 4.995 4.995z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_clear" xmlns="http://www.w3.org/2000/svg"><path d="M32 3.222 19.222 16 32 28.778l-3.221 3.221-12.778-12.778L3.223 31.999.002 28.778 12.78 16 .002 3.222 3.223.001l12.778 12.778L28.779.001z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_cloud_off" xmlns="http://www.w3.org/2000/svg"><path d="M9.023 10.5H7q-1.914 0-3.281 1.395t-1.367 3.309 1.367 3.281T7 19.852h11.375zM3.5 4.976l1.477-1.477L24.5 23.022l-1.477 1.477-2.352-2.297H6.999q-2.898 0-4.949-2.051t-2.051-4.949q0-2.844 1.969-4.867t4.758-2.133zm19.086 5.578q2.242.164 3.828 1.832T28 16.351q0 3.008-2.461 4.758l-1.695-1.695q1.805-.984 1.805-3.063 0-1.422-1.039-2.461t-2.461-1.039h-1.75v-.602q0-2.68-1.859-4.539t-4.539-1.859q-1.531 0-2.953.711l-1.75-1.695Q11.431 3.5 14.001 3.5q2.953 0 5.496 2.078t3.09 4.977z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_code" xmlns="http://www.w3.org/2000/svg"><path d="M9.917 24.5a1.75 1.75 0 1 0-3.501.001 1.75 1.75 0 0 0 3.501-.001zm0-21a1.75 1.75 0 1 0-3.501.001A1.75 1.75 0 0 0 9.917 3.5zm11.666 2.333a1.75 1.75 0 1 0-3.501.001 1.75 1.75 0 0 0 3.501-.001zm1.75 0a3.502 3.502 0 0 1-1.75 3.026c-.055 6.581-4.721 8.039-7.82 9.023-2.898.911-3.846 1.349-3.846 3.117v.474a3.502 3.502 0 0 1 1.75 3.026c0 1.932-1.568 3.5-3.5 3.5s-3.5-1.568-3.5-3.5c0-1.294.711-2.424 1.75-3.026V6.526A3.502 3.502 0 0 1 4.667 3.5c0-1.932 1.568-3.5 3.5-3.5s3.5 1.568 3.5 3.5a3.502 3.502 0 0 1-1.75 3.026v9.06c.93-.456 1.914-.766 2.807-1.039 3.391-1.075 5.323-1.878 5.359-5.687a3.502 3.502 0 0 1-1.75-3.026c0-1.932 1.568-3.5 3.5-3.5s3.5 1.568 3.5 3.5z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_contacts" xmlns="http://www.w3.org/2000/svg"><path d="M22.688 22.688v-2q0-1.5-2.281-2.438t-4.406-.938-4.406.938-2.281 2.438v2h13.375zM16 9q-1.25 0-2.125.875T13 12t.875 2.125T16 15t2.125-.875T19 12t-.875-2.125T16 9zm10.688-3.687q1.063 0 1.844.813t.781 1.875v16q0 1.063-.781 1.875t-1.844.813H5.313q-1.063 0-1.844-.813t-.781-1.875v-16q0-1.063.781-1.875t1.844-.813h21.375zM5.313 32v-2.688h21.375V32H5.313zM26.688 0v2.688H5.313V0h21.375z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_copy" xmlns="http://www.w3.org/2000/svg"><path d="M23.502 25.438V7.626H9.562v17.812h13.94zm0-20.315q1.013 0 1.787.745t.774 1.757v17.812q0 1.013-.774 1.787t-1.787.774H9.562q-1.013 0-1.787-.774t-.774-1.787V7.625q0-1.013.774-1.757t1.787-.745h13.94zM19.689 0v2.562H4.438v17.812H1.936V2.562q0-1.013.745-1.787T4.438.001h15.251z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_create" xmlns="http://www.w3.org/2000/svg"><path d="m31.499 7.167-3.25 3.25-6.666-6.666 3.25-3.25q.5-.5 1.25-.5t1.25.5l4.166 4.166q.5.5.5 1.25t-.5 1.25zM.001 25.333 19.667 5.667l6.666 6.666L6.667 31.999H.001v-6.666z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_dangerous" xmlns="http://www.w3.org/2000/svg"><path d="M21.802 19.833 15.969 14l5.833-5.833-1.969-1.969L14 12.031 8.167 6.198 6.198 8.167 12.031 14l-5.833 5.833 1.969 1.969L14 15.969l5.833 5.833zM19.833 0 28 8.167v11.666L19.833 28H8.167L0 19.833V8.167L8.167 0h11.666z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_date" xmlns="http://www.w3.org/2000/svg"><path d="M27.192 28.844V11.192H4.808v17.652h22.384zm0-25.689q1.277 0 2.253.976t.976 2.253v22.459q0 1.277-.976 2.216t-2.253.939H4.808q-1.352 0-2.291-.901t-.939-2.253V6.385q0-1.277.939-2.253t2.291-.976h1.577V.001h3.23v3.155h12.769V.001h3.23v3.155h1.577zm-3.155 11.267v3.155h-3.23v-3.155h3.23zm-6.46 0v3.155h-3.155v-3.155h3.155zm-6.384 0v3.155h-3.23v-3.155h3.23z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_download" xmlns="http://www.w3.org/2000/svg"><path d="M2.866 28.209h26.269v3.79H2.866v-3.79zm26.268-16.925L16 24.418 2.866 11.284h7.493V.001h11.283v11.283h7.493z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_email" xmlns="http://www.w3.org/2000/svg"><path d="M28.845 9.615v-3.23L16 14.422 3.155 6.385v3.23L16 17.577zm0-6.46q1.277 0 2.216.977T32 6.385v19.23q0 1.277-.939 2.253t-2.216.977H3.155q-1.277 0-2.216-.977T0 25.615V6.385q0-1.277.939-2.253t2.216-.977h25.69z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_error_outline" xmlns="http://www.w3.org/2000/svg"><path d="M14 25.239q4.601 0 7.92-3.319T25.239 14 21.92 6.08 14 2.761 6.08 6.08 2.761 14t3.319 7.92T14 25.239zM14 0q5.784 0 9.892 4.108T28 14t-4.108 9.892T14 28t-9.892-4.108T0 14t4.108-9.892T14 0zm-1.38 6.967h2.761v8.413H12.62V6.967zm0 11.239h2.761v2.826H12.62v-2.826z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_fire" xmlns="http://www.w3.org/2000/svg"><path d="M17.689 21.998q-.32.32-.8.576t-.864.384q-1.152.384-2.272.032t-1.888-.992q-.128-.128-.096-.256t.16-.192q1.216-.384 1.92-1.216t.96-1.792q.192-.896-.064-1.728t-.384-1.728q-.128-.704-.096-1.376t.288-1.312q0-.128.128-.128t.192.064q.384.832.992 1.472t1.28 1.216 1.216 1.248.672 1.568q.064.384.064.704.064.96-.32 1.92t-1.088 1.536zm3.84-10.944q-.768-.704-1.6-1.28t-1.6-1.344q-1.536-1.536-2.016-3.584t.16-4.16q.128-.32-.096-.544t-.544-.096q-.768.32-1.44.768t-1.312.896q-1.984 1.664-3.136 3.936T8.633 10.51t.8 5.088q0 .128.032.256t.032.256q0 .576-.512.832t-1.024-.192q-.128-.192-.192-.32-1.024-1.28-1.376-2.912t-.096-3.232q.064-.384-.288-.576t-.608.128q-1.28 1.664-1.856 3.68t-.448 4.064q0 .576.096 1.184t.288 1.184q.448 1.536 1.216 2.816 1.216 2.048 3.264 3.424t4.416 1.696q2.496.32 5.024-.256t4.448-2.304q1.408-1.344 2.208-3.104t.864-3.68-.704-3.712q-.064-.128-.096-.224t-.096-.224q-.576-1.088-1.28-1.984-.256-.384-.544-.704t-.672-.64z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_git" xmlns="http://www.w3.org/2000/svg"><path d="M27.472 12.753 15.247.529a1.803 1.803 0 0 0-2.55 0l-2.84 2.84 2.137 2.137a2.625 2.625 0 0 1 3.501 3.501l3.499 3.499a2.625 2.625 0 1 1-1.237 1.237l-3.499-3.499c-.083.04-.169.075-.257.106v7.3a2.626 2.626 0 1 1-1.75 0v-7.3a2.626 2.626 0 0 1-1.494-3.607L8.62 4.606l-8.09 8.09a1.805 1.805 0 0 0 0 2.551l12.225 12.224a1.803 1.803 0 0 0 2.55 0l12.168-12.168a1.805 1.805 0 0 0 0-2.551z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_gitea" xmlns="http://www.w3.org/2000/svg"><path d="M5.581 7.229c-2.46-.005-5.755 1.559-5.573 5.48.284 6.125 6.56 6.693 9.068 6.743.275 1.149 3.227 5.112 5.412 5.32h9.573c5.741-.381 10.04-17.363 6.853-17.427-5.271.248-8.395.373-11.073.395v5.3l-.835-.369-.005-4.928c-3.075-.001-5.781-.144-10.919-.397-.643-.004-1.539-.113-2.501-.116zm.348 2.166h.293c.349 3.14.917 4.976 2.067 7.781-2.933-.347-5.429-1.199-5.888-4.38-.237-1.647.563-3.365 3.528-3.401zm11.409 3.087c.2.003.404.04.596.128l.999.431-.716 1.305h-.007a.996.996 0 0 0-.321.053l.006-.002c-.349.114-.593.406-.593.749 0 .097.019.189.055.275l-.002-.006a.767.767 0 0 0 .151.233l-.001-.001-1.235 2.248a.99.99 0 0 0-.302.052l.006-.002c-.349.114-.593.406-.593.749 0 .097.019.189.055.275l-.002-.006c.128.31.457.527.843.527a.987.987 0 0 0 .31-.049l-.006.002c.348-.114.592-.406.592-.749 0-.097-.02-.19-.056-.277l.002.006a.784.784 0 0 0-.211-.293l1.203-2.189a.999.999 0 0 0 .397-.041l-.006.002a.942.942 0 0 0 .285-.15l-.001.001c.464.195.844.353 1.117.488.411.203.556.337.6.487.044.147-.004.429-.236.925-.173.369-.46.893-.799 1.511h-.02a.991.991 0 0 0-.321.053l.006-.002c-.349.114-.593.406-.593.749 0 .097.019.189.055.275l-.002-.006c.128.31.457.527.843.527a.987.987 0 0 0 .31-.049l-.006.002c.348-.114.592-.406.592-.749a.703.703 0 0 0-.055-.275l.002.006a.802.802 0 0 0-.183-.27l.001.001c.335-.611.623-1.136.808-1.531.251-.536.381-.935.267-1.32s-.467-.636-.933-.867c-.307-.151-.689-.311-1.147-.503a.723.723 0 0 0-.052-.324l.002.006a.792.792 0 0 0-.194-.279l.704-1.284 3.899 1.684c.704.305.995 1.053.653 1.68l-2.68 4.907c-.343.625-1.184.884-1.888.58l-5.516-2.384c-.704-.304-.996-1.053-.653-1.68l2.68-4.905c.235-.431.707-.687 1.207-.707z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_github" xmlns="http://www.w3.org/2000/svg"><path d="M16 .394c8.833 0 15.999 7.166 15.999 15.999 0 7.062-4.583 13.062-10.937 15.187-.813.146-1.104-.354-1.104-.771 0-.521.021-2.25.021-4.396 0-1.5-.5-2.458-1.083-2.958 3.562-.396 7.312-1.75 7.312-7.896 0-1.75-.625-3.167-1.646-4.291.167-.417.708-2.042-.167-4.25-1.333-.417-4.396 1.646-4.396 1.646a15.032 15.032 0 0 0-8 0S8.937 6.602 7.603 7.018c-.875 2.208-.333 3.833-.167 4.25-1.021 1.125-1.646 2.542-1.646 4.291 0 6.125 3.729 7.5 7.291 7.896-.458.417-.875 1.125-1.021 2.146-.917.417-3.25 1.125-4.646-1.333-.875-1.521-2.458-1.646-2.458-1.646-1.562-.021-.104.979-.104.979 1.042.479 1.771 2.333 1.771 2.333.938 2.854 5.396 1.896 5.396 1.896 0 1.333.021 2.583.021 2.979 0 .417-.292.917-1.104.771C4.582 29.455-.001 23.455-.001 16.393-.001 7.56 7.165.394 15.998.394zM6.063 23.372c.042-.083-.021-.187-.146-.25-.125-.042-.229-.021-.271.042-.042.083.021.187.146.25.104.062.229.042.271-.042zm.646.709c.083-.062.062-.208-.042-.333-.104-.104-.25-.146-.333-.062-.083.062-.062.208.042.333.104.104.25.146.333.062zm.625.937c.104-.083.104-.25 0-.396-.083-.146-.25-.208-.354-.125-.104.062-.104.229 0 .375s.271.208.354.146zm.875.875c.083-.083.042-.271-.083-.396-.146-.146-.333-.167-.417-.062-.104.083-.062.271.083.396.146.146.333.167.417.062zm1.187.521c.042-.125-.083-.271-.271-.333-.167-.042-.354.021-.396.146s.083.271.271.312c.167.062.354 0 .396-.125zm1.313.104c0-.146-.167-.25-.354-.229-.187 0-.333.104-.333.229 0 .146.146.25.354.229.187 0 .333-.104.333-.229zm1.208-.208c-.021-.125-.187-.208-.375-.187-.187.042-.312.167-.292.312.021.125.187.208.375.167s.312-.167.292-.292z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_gitlab" xmlns="http://www.w3.org/2000/svg"><path d="M1.629 11.034 14 26.888.442 17.048a1.09 1.09 0 0 1-.39-1.203l1.578-4.811zm7.217 0h10.309l-5.154 15.854zM5.753 1.475l3.093 9.559H1.63l3.093-9.559a.548.548 0 0 1 1.031 0zm20.618 9.559 1.578 4.811c.141.437-.016.922-.39 1.203l-13.558 9.84 12.371-15.854zm0 0h-7.216l3.093-9.559a.548.548 0 0 1 1.031 0z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_heart" xmlns="http://www.w3.org/2000/svg"><path d="M16 29.714a1.11 1.11 0 0 1-.786-.321L4.072 18.643c-.143-.125-4.071-3.714-4.071-8 0-5.232 3.196-8.357 8.535-8.357 3.125 0 6.053 2.464 7.464 3.857 1.411-1.393 4.339-3.857 7.464-3.857 5.339 0 8.535 3.125 8.535 8.357 0 4.286-3.928 7.875-4.089 8.035L16.785 29.392c-.214.214-.5.321-.786.321z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_info_outline" xmlns="http://www.w3.org/2000/svg"><path d="M12.62 9.793V6.967h2.761v2.826H12.62zM14 25.239q4.601 0 7.92-3.319T25.239 14 21.92 6.08 14 2.761 6.08 6.08 2.761 14t3.319 7.92T14 25.239zM14 0q5.784 0 9.892 4.108T28 14t-4.108 9.892T14 28t-9.892-4.108T0 14t4.108-9.892T14 0zm-1.38 21.033V12.62h2.761v8.413H12.62z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_keyboard_arrow_down" xmlns="http://www.w3.org/2000/svg"><path d="M3.281 5.36 14 16.079 24.719 5.36 28 8.641l-14 14-14-14z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_keyboard_arrow_left" xmlns="http://www.w3.org/2000/svg"><path d="M25.875 28.25 22.125 32 6.126 16.001 22.125.002l3.75 3.75-12.25 12.25z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_keyboard_arrow_right" xmlns="http://www.w3.org/2000/svg"><path d="M6.125 28.25 18.375 16 6.125 3.75 9.875 0l15.999 15.999L9.875 31.998z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_keyboard_arrow_up" xmlns="http://www.w3.org/2000/svg"><path d="M24.719 22.64 14 11.921 3.281 22.64 0 19.359l14-14 14 14z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_link" xmlns="http://www.w3.org/2000/svg"><path d="M24.037 7.963q3.305 0 5.634 2.366T32 16t-2.329 5.671-5.634 2.366h-6.46v-3.08h6.46q2.028 0 3.493-1.465t1.465-3.493-1.465-3.493-3.493-1.465h-6.46v-3.08h6.46zM9.615 17.578v-3.155h12.77v3.155H9.615zM3.005 16q0 2.028 1.465 3.493t3.493 1.465h6.46v3.08h-6.46q-3.305 0-5.634-2.366T0 16.001t2.329-5.671 5.634-2.366h6.46v3.08h-6.46q-2.028 0-3.493 1.465t-1.465 3.493z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_mastodon" xmlns="http://www.w3.org/2000/svg"><path d="M30.924 10.506c0-6.941-4.548-8.976-4.548-8.976C24.083.477 20.144.034 16.054.001h-.101C11.862.034 7.926.477 5.633 1.53c0 0-4.548 2.035-4.548 8.976 0 1.589-.031 3.491.02 5.505.165 6.79 1.245 13.479 7.522 15.14 2.893.765 5.379.927 7.38.816 3.629-.2 5.667-1.296 5.667-1.296l-.12-2.633s-2.593.817-5.505.719c-2.887-.099-5.932-.311-6.399-3.855a7.069 7.069 0 0 1-.064-.967v-.028.001s2.833.693 6.423.857c2.195.1 4.253-.129 6.344-.377 4.009-.479 7.5-2.949 7.939-5.207.689-3.553.633-8.676.633-8.676zm-5.366 8.945h-3.329v-8.159c0-1.72-.724-2.592-2.171-2.592-1.6 0-2.403 1.035-2.403 3.083v4.465h-3.311v-4.467c0-2.048-.803-3.083-2.403-3.083-1.447 0-2.171.873-2.171 2.592v8.159H6.441v-8.404c0-1.719.437-3.084 1.316-4.093.907-1.011 2.092-1.528 3.565-1.528 1.704 0 2.995.655 3.848 1.965l.828 1.391.829-1.391c.853-1.311 2.144-1.965 3.848-1.965 1.472 0 2.659.517 3.565 1.528.877 1.009 1.315 2.375 1.315 4.093z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_matrix" xmlns="http://www.w3.org/2000/svg"><path d="M.843.734v30.532H3.04v.733H0V0h3.04v.733zm9.391 9.68v1.543h.044a4.417 4.417 0 0 1 1.489-1.365c.577-.327 1.248-.487 2-.487.72 0 1.377.143 1.975.419.597.277 1.047.776 1.36 1.477.339-.499.8-.941 1.379-1.323.579-.383 1.267-.573 2.061-.573.604 0 1.163.075 1.68.223a3.34 3.34 0 0 1 1.324.707c.368.327.652.745.861 1.268.203.523.307 1.151.307 1.889v7.637h-3.132v-6.468c0-.381-.013-.745-.043-1.083a2.315 2.315 0 0 0-.246-.893l.006.013a1.484 1.484 0 0 0-.577-.593l-.007-.004c-.259-.147-.609-.221-1.047-.221-.443 0-.8.085-1.071.252-.267.166-.483.39-.635.656l-.005.009a2.558 2.558 0 0 0-.307.915l-.002.013a7.156 7.156 0 0 0-.08 1.044v6.359h-3.133v-6.4c0-.339-.005-.671-.024-1.003a2.772 2.772 0 0 0-.197-.936l.007.019a1.41 1.41 0 0 0-.548-.667l-.006-.003c-.259-.167-.635-.253-1.139-.253-.148 0-.345.032-.585.099-.24.068-.48.191-.707.376-.228.184-.425.449-.585.793-.16.345-.24.8-.24 1.36v6.621H7.279v-11.42zm20.923 20.852V.734H28.96V.001H32V32h-3.04v-.733z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_menu" xmlns="http://www.w3.org/2000/svg"><path d="M.001 5.334h31.998v3.583H.001V5.334zm0 12.416v-3.5h31.998v3.5H.001zm0 8.916v-3.583h31.998v3.583H.001z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_notifications" xmlns="http://www.w3.org/2000/svg"><path d="m25.846 22.154 3.308 3.308v1.615H2.847v-1.615l3.308-3.308V14q0-3.846 1.961-6.692t5.423-3.692V2.462q0-1 .692-1.731T16 0t1.769.731.692 1.731v1.154q3.461.846 5.423 3.692T25.846 14v8.154zM16 32q-1.385 0-2.346-.923t-.962-2.308h6.615q0 1.308-1 2.269T15.999 32z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_person" xmlns="http://www.w3.org/2000/svg"><path d="M16 20.023q5.052 0 10.526 2.199t5.473 5.754v4.023H0v-4.023q0-3.555 5.473-5.754t10.526-2.199zM16 16q-3.275 0-5.614-2.339T8.047 8.047t2.339-5.661T16 0t5.614 2.386 2.339 5.661-2.339 5.614T16 16z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_pin" xmlns="http://www.w3.org/2000/svg"><path d="M17.6 19.2h9.6v-1.6L22.4 16V3.2l4.8-1.6V0H4.8v1.6l4.8 1.6V16l-4.8 1.6v1.6h9.6v11.2L16 32l1.6-1.6V19.2z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_rss_feed" xmlns="http://www.w3.org/2000/svg"><path d="M-.481 12.048q8.482 0 14.457 5.976t5.976 14.457h-5.879q0-5.976-4.289-10.264T-.48 17.928v-5.879zm0-11.565q13.204 0 22.601 9.397t9.397 22.601h-5.783q0-10.891-7.662-18.553T-.481 6.266V.483zm0 27.468q0-1.831 1.301-3.132t3.229-1.301 3.181 1.253 1.253 3.181-1.301 3.229-3.132 1.301q-1.928 0-3.229-1.301T-.48 27.952z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_search" xmlns="http://www.w3.org/2000/svg"><path d="M11.925 20.161q3.432 0 5.834-2.402t2.402-5.834-2.402-5.834-5.834-2.402-5.834 2.402-2.402 5.834 2.402 5.834 5.834 2.402zm10.981 0L32 29.255 29.255 32l-9.094-9.094v-1.458l-.515-.515q-3.26 2.831-7.721 2.831-4.976 0-8.45-3.432T.001 11.925t3.474-8.45 8.45-3.474 8.407 3.474 3.432 8.45q0 1.802-.858 4.075t-1.973 3.646l.515.515h1.458z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_security" xmlns="http://www.w3.org/2000/svg"><path d="m16 0 13.072 5.855v8.715q0 6.059-3.745 11.063T16 31.999q-5.583-1.362-9.327-6.366T2.928 14.57V5.855zm0 16v13.004q4.017-1.294 6.808-4.868T26.144 16H16zm0 0V3.2L5.856 7.693v8.306H16z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_star" xmlns="http://www.w3.org/2000/svg"><path d="M14 22.052 5.324 27.31l2.3-9.859L0 10.813l10.056-.854L14 .692l3.944 9.267L28 10.813l-7.624 6.638 2.3 9.859z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_tag" xmlns="http://www.w3.org/2000/svg"><path d="M17.52 17.52v-7.041h-7.041v7.041h7.041zM28 10.479h-7.041v7.041H28v3.439h-7.041V28H17.52v-7.041h-7.041V28H7.04v-7.041H-.001V17.52H7.04v-7.041H-.001V7.04H7.04V-.001h3.439V7.04h7.041V-.001h3.439V7.04H28v3.439z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_timer" xmlns="http://www.w3.org/2000/svg"><path d="M16 29q4.428 0 7.536-3.143t3.107-7.571-3.107-7.536T16 7.643 8.464 10.75t-3.107 7.536 3.107 7.571T16 29zM26.714 9.786q1.214 1.571 2.107 4.036t.893 4.464q0 5.643-4 9.678T16 32t-9.714-4.036-4-9.678 4-9.678T16 4.572q1.929 0 4.464.929t4.107 2.143l2.143-2.214q1.143.929 2.143 2.143zM14.5 19.857v-9.143h3v9.143h-3zM20.571.001v3.071h-9.143V.001h9.143z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_tree" xmlns="http://www.w3.org/2000/svg"><path d="M32 14.423H20.808V9.616h-3.23v12.77h3.23v-4.807H32v12.845H20.808v-4.807h-6.385v-16h-3.23v4.807H.001V1.579h11.192v4.807h9.615V1.579H32v12.845z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_xmpp" xmlns="http://www.w3.org/2000/svg"><path d="M31.995 4.237c-.449.175-1.12.433-1.936.745-1.544.591-2.328.891-2.924 1.093-.613.208-1.287.409-2.635.813-.911.272-1.672.495-2.212.651-.031.875 0 2.177-.292 3.635a21.837 21.837 0 0 1-2.016 5.765c-1.496 2.944-3.236 4.817-3.88 5.476-.056-.059-.112-.117-.168-.179-.707-.763-2.403-2.703-3.815-5.683-1.053-2.223-1.484-4.044-1.605-4.584-.356-1.589-.427-2.955-.427-4.117 0-.075-.036-.129-.101-.149-.721-.223-1.765-.519-2.887-.853-1.271-.379-2.193-.744-3.408-1.2-.493-.185-1.409-.547-2.217-.859C.723 4.499.113 4.236.041 4.236c-.005 0-.015 0-.023.012a.131.131 0 0 0-.019.076c.009.593.08 1.361.256 2.365.615 3.503 2.688 7.061 4.36 9.244 0 0 3.717 5.035 9.128 8.144l.303.176c-.009.008-.02.015-.028.021-1.717 1.316-3.201 1.977-3.579 2.14a15.71 15.71 0 0 1-2.219.772v.407a25.31 25.31 0 0 0 2.72-.487 26.72 26.72 0 0 0 5.075-1.792c.136.067.276.136.42.204 1.527.725 3.571 1.627 6.073 2.048.613.103 1.136.165 1.507.195a.109.109 0 0 0 .115-.091.55.55 0 0 0 .004-.217.107.107 0 0 0-.063-.073c-.505-.209-1.201-.4-1.983-.719-.935-.381-2.241-1.067-3.648-2.128a13.528 13.528 0 0 1-.367-.287c4.64-2.656 7.989-6.588 7.989-6.588 1.735-2.036 4.441-5.623 5.431-9.795.349-1.473.539-2.741.5-3.628z"/></svg></defs></svg>




    <div
      class="wrapper "
    >
      <header class="gblog-header">
  <div class="container flex flex-wrap">
    <div class="gblog-header__col-1 flex justify-start hidden-mobile"></div>
    <div class="gblog-header__col-2 flex align-center justify-center ">
      <a class="gblog-header__link" rel="me" href="https://valmat.ru/">
        <span class="gblog-brand flex align-center justify-center">
          
          <span class="gblog-brand__title">Valmat&#39;s Personal Blog</span>
        </span>
        
      </a>
    </div>
    <div class="gblog-header__col-3 flex justify-end">
      <span id="gblog-color-theme">
        <svg class="gblog-icon gblog_brightness_dark">
          <title>Toggle Dark/Light/Auto mode</title>
          <use xlink:href="#gblog_brightness_dark"></use>
        </svg>
        <svg class="gblog-icon gblog_brightness_light">
          <title>Toggle Dark/Light/Auto mode</title>
          <use xlink:href="#gblog_brightness_light"></use>
        </svg>
        <svg class="gblog-icon gblog_brightness_auto">
          <title>Toggle Dark/Light/Auto mode</title>
          <use xlink:href="#gblog_brightness_auto"></use>
        </svg>
      </span>
    </div>
  </div>
</header>
<nav class="gblog-nav">
  <input type="checkbox" id="menu-control" class="hidden" />
  <div class="gblog-nav__control">
    <label for="menu-control" class="flex align-center justify-center">
      <svg class="gblog-icon gblog_menu"><use xlink:href="#gblog_menu"></use></svg>
      <svg class="gblog-icon gblog_clear"><use xlink:href="#gblog_clear"></use></svg>
      <span>Navigation</span>
    </label>
  </div>
  <ul class="gblog-nav__list container flex flex-wrap justify-center menu-content">
    
    
      
        
          <li>
            <a
              class="gblog-nav__entry"
              href="/tags/AI/"
            >
              Ai
            </a>
          </li>
        
      
        
          <li>
            <a
              class="gblog-nav__entry"
              href="/tags/algo/"
            >
              Algo
            </a>
          </li>
        
      
        
          <li>
            <a
              class="gblog-nav__entry"
              href="/tags/archive/"
            >
              Archive
            </a>
          </li>
        
      
        
          <li>
            <a
              class="gblog-nav__entry"
              href="/tags/cpp/"
            >
              Cpp
            </a>
          </li>
        
      
        
          <li>
            <a
              class="gblog-nav__entry"
              href="/tags/LLM/"
            >
              Llm
            </a>
          </li>
        
      
        
          <li>
            <a
              class="gblog-nav__entry"
              href="/tags/thoughts/"
            >
              Thoughts
            </a>
          </li>
        
      
        
          <li>
            <a
              class="gblog-nav__entry"
              href="/tags/useful/"
            >
              Useful
            </a>
          </li>
        
      
    
    
  </ul>
</nav>



      <main class="gblog-page container">
        
  <article class="gblog-post">
    <header class="gblog-post__header">
      
      

      


      <h1 class="gblog-post__title">Получение распределений в задачах регрессии</h1>

      
        <div class="flex flex-wrap align-center gblog-post__meta gblog-post__meta--head">
          <span class="flex align-center no-wrap gblog-post__meta--update">
  <svg class="gblog-icon gblog_date"><use xlink:href="#gblog_date"></use></svg>
  <span class="gblog-post__tag">
    <time datetime="2022-09-20T12:00:00&#43;03:00">
      
      Sep 20, 2022
    </time>
  </span>
</span>

<span class="flex align-center no-wrap gblog-post__meta--readtime">
  <svg class="gblog-icon gblog_timer"><use xlink:href="#gblog_timer"></use></svg>
  <span class="gblog-post__tag">9 min read</span>
</span>








  
    
    
      
        <span class="flex align-center no-wrap gblog-post__meta--tag">
          <svg class="gblog-icon gblog_bookmark"><use xlink:href="#gblog_bookmark"></use></svg>
          
  <span class="gblog-post__tag gblog-button gblog-button--regular">
    <a
      class="gblog-button__link"
      href="/tags/AI/"
      title="All posts tagged with 'AI'"
    >
      AI
    </a>
  </span>

        </span>
      
    
    
  
    
    
      
        <span class="flex align-center gblog-post__meta--tag">
          
  <span class="gblog-post__tag gblog-button gblog-button--regular">
    <a
      class="gblog-button__link"
      href="/tags/algo/"
      title="All posts tagged with 'algo'"
    >
      algo
    </a>
  </span>

        </span>
      
    
    
  













        </div>
      
    </header>
    <section class="gblog-markdown">
      <p>Приводится алгоритм нахождения функций распределения в качестве решения задачи регрессии.</p>
<p>В общем виде задачу регрессии можно сформулировать как восстановление зависимости<br>
$\phi: X \to L_1(\Omega)$,<br>
сопоставляющей элементам некоторого фазового пространства $X$ случайную величину $\xi \in L_1(\Omega)$.</p>
<p>Классический подход к решению задачи регрессии состоит в нахождении среднего значения $E[\phi(x)]$ для каждого $x \in X$.</p>
<p>В статье предлагается простой алгоритм оценки распределений случайных величин $\phi(x) \in L_1(\Omega)$.</p>
<p><a
  class="gblog-markdown__link"
  href="https://github.com/valmat"
>GitHub</a></p>
<hr>



  <div class="gblog-toc gblog-toc__level--6">
    <nav id="TableOfContents"><ul>
        <li><a href="#мотивация">Мотивация</a></li>
        <li><a href="#описание-подхода">Описание подхода</a>
          <ul>
            <li><a href="#постановка-задачи">Постановка задачи</a></li>
            <li><a href="#построение-модели">Построение модели</a></li>
            <li><a href="#ограничения">Ограничения</a></li>
          </ul>
        </li>
        <li><a href="#итоговый-алгоритм">Итоговый алгоритм</a></li>
        <li><a href="#валидация">Валидация</a></li>
        <li><a href="#эксперименты">Эксперименты</a></li>
        <li><a href="#заключение">Заключение</a></li>
      </ul></nav>
    <hr />
  </div>


<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="мотивация"
    >
        Мотивация
    </h2>
    <a data-clipboard-text="https://valmat.ru/posts/2022/09/regress-distr/#мотивация" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Мотивация" href="#%d0%bc%d0%be%d1%82%d0%b8%d0%b2%d0%b0%d1%86%d0%b8%d1%8f">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>В анализе данных значительное место занимают два класса задач — задачи классификации и регрессии.</p>
<p>Так сложилось, что, хотя эти задачи очень похожи, подход к их решению отличается.</p>
<p>Большинство алгоритмов решения задач <strong>классификации</strong> позволяют не просто оценить среднее значение $E[\phi(x)]$ для каждого элемента фазового пространства $X$, но и найти плотность распределения.</p>
<p>Для задач <strong>регрессии</strong> обычно находят лишь некоторую числовую оценку $\widehat{\phi(x)}$, которая, чаще всего, является средним значением, но не находят плотность распределения.</p>
<p>Знание плотности распределения даёт гораздо больше возможностей для принятия решений, чем просто оценка среднего.</p>
<p>Например, для заданной точки $x \in X$ мы можем:</p>
<ul>
<li>Оценить уверенность прогноза в каждой конкретной точке.</li>
<li>Найти не среднее, а наиболее вероятное значение случайной величины. Это особенно актуально, если распределение $\phi(x)$ является мультимодальным.</li>
<li>Определить доверительный интервал возможных значений оценки $\widehat{\phi(x)}$.</li>
<li>Вычислить любые характеристики распределения, определяемые конкретной задачей и позволяющие более взвешенно и точно принимать решения на основе прогноза модели.</li>
</ul>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="описание-подхода"
    >
        Описание подхода
    </h2>
    <a data-clipboard-text="https://valmat.ru/posts/2022/09/regress-distr/#описание-подхода" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Описание подхода" href="#%d0%be%d0%bf%d0%b8%d1%81%d0%b0%d0%bd%d0%b8%d0%b5-%d0%bf%d0%be%d0%b4%d1%85%d0%be%d0%b4%d0%b0">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="постановка-задачи"
    >
        Постановка задачи
    </h3>
    <a data-clipboard-text="https://valmat.ru/posts/2022/09/regress-distr/#постановка-задачи" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Постановка задачи" href="#%d0%bf%d0%be%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0-%d0%b7%d0%b0%d0%b4%d0%b0%d1%87%d0%b8">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Для простоты опишу подход для одномерной задачи регрессии. В многомерном случае подход аналогичен.</p>
<p>Имеем некоторое фазовое пространство $X$ и закономерность</p>
<p>$$
\phi: X \to L_1(\Omega, \mathbb{R})
$$</p>
<p>$\phi$ сопоставляет случайные величины из $L_1(\Omega)$ точкам фазового пространства $X$.</p>
<p>Таким образом, мы имеем семейство вероятностных мер $\lbrace P_x\rbrace_{x \in X}$, порождаемых закономерностью $\phi$.</p>
<p>Нам нужно построить модель, порождающую параметрическое семейство вероятностных мер</p>
<p>$$
\lbrace Q_{x, \theta}\rbrace_{x \in X, \theta \in \Theta}
$$</p>
<p>и найти оптимальное значение параметра $\theta_0 \in \Theta$, дающее наилучшее, в некотором смысле, приближение реальных распределений $\lbrace P_x\rbrace_{x \in X}$:</p>
<p>$$
Q_{x, \theta_0} \sim P_x
$$</p>
<p>При этом мы располагаем выборкой точек $\lbrace(x_i, y_i)\rbrace_{i=1}^N$, порожденной $N$ независимыми испытаниями: $x_i \in X$, $y_i = \phi(x_i)$.</p>
<p>$y_i \in L_1(\Omega)$ — являются независимыми случайными величинами. $x_i \in X$, в общем случае, случайными величинами могут и не быть.</p>
<p>Чтобы понять как строить модель, решающую поставленную задачу, посмотрим как она решается в случае задач классификации.</p>
<p>В приведенной выше постановке задачи единственным отличием задачи классификации от задачи регрессии является то, что для задач классификации вероятностное пространство $L_1(\Omega)$ является дискретным.</p>
<p>Когда задача моделирования распределения решается для дискретного $L_1(\Omega)$, т.е. для классификации, реальную плотность распределения приближают функциями вида</p>
<p>$$
\sum_{k=1}^K  \mathbf{1}_{A_k}
$$</p>
<p>где $A_k \subseteq \Omega$, $\mathbf{1}_{A}$ — характеристическая функция множества $A$.</p>
<p>Именно так мы и поступим.</p>
<p>Только для решения задачи регрессии моделировать лучше не плотность, а функцию распределения. На это есть ряд причин.</p>
<p>Во-первых, использование функции распределения является более робастным, чем использование плотности.</p>
<p>Во-вторых, плотность распределения должна удовлетворять свойству $\int_{\mathbb{R}} p(t) dt = 1$. Это свойство может быть сложнее удовлетворить при построении модели, чем соответствующее ограничение на функцию распределения:</p>
<p>$$
\lim\limits_{t \to -\infty}F(t) = 0, \
\lim\limits_{t \to +\infty}F(t) = 1.
$$</p>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="построение-модели"
    >
        Построение модели
    </h3>
    <a data-clipboard-text="https://valmat.ru/posts/2022/09/regress-distr/#построение-модели" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Построение модели" href="#%d0%bf%d0%be%d1%81%d1%82%d1%80%d0%be%d0%b5%d0%bd%d0%b8%d0%b5-%d0%bc%d0%be%d0%b4%d0%b5%d0%bb%d0%b8">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Вместо привычной для регрессии модели</p>
<p>$$
M_{\theta}: X \to \mathbb{R}
$$</p>
<p>и последующего нахождения $\theta$ путём оптимизации, будем строить модель, сразу приближающую функции распределения:</p>
<p>$$
M_{\theta}: X \to (\mathbb{R} \to [0, 1])
$$</p>
<p>или, что то же самое:</p>
<p>$$
M_{\theta}: X \times \mathbb{R} \to [0, 1]
$$</p>
<p>То есть каждой паре $(x, t)$, $x \in X, t \in \mathbb{R}$, наша модель будет сопоставлять число в интервале $[0, 1]$.</p>
<p>Например, для нейронных сетей этого легко добиться, поместив сигмоиду последним слоем сети.</p>
<p>Информация о реальном семействе распределений $\lbrace P_x \rbrace_{x \in X}$, которой мы располагаем, отражена в имеющейся у нас обучающей выборке $\lbrace(x_i, y_i)\rbrace_{i=1}^N$.</p>
<p>Эта обучающая выборка порождает набор тривиальных функций распределения $\lbrace F_i\rbrace_{i=1}^N$:</p>
<p>$$
F_i(t) =
\begin{cases}
1, &amp; t \geqslant y_i |\
0, &amp; t &lt; y_i
\end{cases}
$$</p>
<p>$F_i(t) = 1$, при $t \geqslant y_i$, и $F_i(t) = 0$, при $t &lt; y_i$.</p>
<p>Чтобы уйти от задачи построения модели, аппроксимирующей выборку функций, к хорошо изученной задаче построения модели, аппроксимирующей выборку точек, перейдем от выборки $\lbrace(x_i, y_i)\rbrace_{i=1}^N$ к выборке</p>
<p>$$
\bigcup\limits_{i=1}^N \lbrace(x_i, t_j, F_i(t_j))\rbrace_{j \in J_i}
$$</p>
<p>Для этого для каждого $i = 1&hellip;N$ случайным образом подберём числа $t_j$ для $j \in J_i$ из некоторого диапазона допустимых значений $y$.</p>
<p>Таким образом, мы снова приходим к классической задаче регрессии, но фазовым пространством для нее будет не исходное пространство $X$, а пространство $X \times Y$, где $Y \subseteq \mathbb{R}$ — множество допустимых значений $y$.</p>
<p>То есть мы получили обычную задачу регрессии для выборки $\lbrace(z_k, u_k)\rbrace_{k=1}^M$, где<br>
$z_k = (x_l, t_s)$, а $u_k = F_l(t_s) \in [0, 1]$, для некоторых $l$ и $s$.</p>
<p>Для решения этой задачи можно применить любой алгоритм обучения с учителем из арсенала методов решения задач регрессии.</p>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="ограничения"
    >
        Ограничения
    </h3>
    <a data-clipboard-text="https://valmat.ru/posts/2022/09/regress-distr/#ограничения" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Ограничения" href="#%d0%be%d0%b3%d1%80%d0%b0%d0%bd%d0%b8%d1%87%d0%b5%d0%bd%d0%b8%d1%8f">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Поскольку описанный выше способ моделирует построение функций распределения, наша модель должна удовлетворять некоторым дополнительным ограничениям.</p>
<p>Пусть</p>
<p>$$
M_{\theta}: X \times Y \to [0, 1], \theta \in \Theta
$$</p>
<p>— параметрическое семейство моделей, и $\theta_0$ — оптимальная оценка параметра, дающая приближение реального семейства распределений $\lbrace P_x\rbrace_{x \in X}$, и</p>
<p>$$
M = \lim\limits_{\theta \to \theta_0, \theta \in \Theta} M_{\theta}
$$</p>
<p>— итоговая модель.</p>
<p>Тогда должны быть выполнены требования:</p>
<ul>
<li>Для каждого $x \in X$ $M(x, \cdot): t \to [0, 1] $ — является функцией некоторого распределения.</li>
</ul>
<p>То есть должны быть удовлетворены следующие условия:</p>
<ol>
<li>$\lim\limits_{t \to -\infty} M(x ,t) = 0$,<br>
$\lim\limits_{t \to +\infty} M(x ,t) = 1$</li>
<li>$t_1 \leqslant t_2 \Rightarrow M(x, t_1) \leqslant M(x, t_2)$</li>
<li>$M(x, t) \in [0, 1],, \forall t \in \mathbb{R}$</li>
</ol>
<p>Все эти условия, в общем случае, не обязаны выполняться по построению моделей $M_{\theta}$ способом, описанным выше.</p>
<p>Условие (3) может быть удовлетворено путём наложения ограничений на саму модель. Например, для нейронных сетей можно последним слоем разместить сигмоиду.</p>
<p>Практика показала, что для правильно построенной модели при достаточном объеме обучающей выборки условия (1) и (2) будут выполнены автоматически. Но эти условия должны быть вынесены на этап валидации в качестве дополнительного обязательного критерия правильности построения модели.</p>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="итоговый-алгоритм"
    >
        Итоговый алгоритм
    </h2>
    <a data-clipboard-text="https://valmat.ru/posts/2022/09/regress-distr/#итоговый-алгоритм" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Итоговый алгоритм" href="#%d0%b8%d1%82%d0%be%d0%b3%d0%be%d0%b2%d1%8b%d0%b9-%d0%b0%d0%bb%d0%b3%d0%be%d1%80%d0%b8%d1%82%d0%bc">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Кратко опишем алгоритм.</p>
<p>Дана обучающая выборка $\lbrace(x_i, y_i)\rbrace_{i=1}^N$.</p>
<ol>
<li>
<p><strong>Находим диапазон допустимых значений $Y$.</strong><br>
Например,
$$
Y = [\min\limits_{i} y_i - a, \max\limits_{i} y_i + a],
$$
где $a$ — некоторое число, подбираемое исследователем.</p>
</li>
<li>
<p><strong>Для каждой пары $(x_i, y_i)$ случайно генерируем набор точек $\lbrace t_j\rbrace_{j \in J_i} \subseteq Y$.</strong><br>
$\lbrace t_j\rbrace$ нужно генерировать так, чтобы было достаточно точек, лежащих левее $y_i$ и достаточно точек, лежащих правее $y_i$.<br>
Можно задать разбиение $\lbrace t_j\rbrace_{j \in J} \subseteq Y$ одинаковое для всех $i$, но тогда мы теряем разнообразие обучающей выборки в тех случаях, когда $(x_i, y_i)$ и $(x_k, y_k)$ — близкие, но не совпадающие точки.</p>
</li>
<li>
<p><strong>После того, как точки $\lbrace t_j\rbrace_{j \in J_i}$ сгенерированы, генерируем новую обучающую выборку, как объединение выборок:</strong></p>
<p>$$
\bigcup\limits_{i=1}^N \lbrace(x_i, t_j, u_{i j})\rbrace_{j \in J_i}
$$</p>
<p>где</p>
<p>$$
u_{i j} =
\begin{cases}
1, &amp; t_j \geqslant y_i |\
0, &amp; t_j &lt; y_i
\end{cases}
$$</p>
<p>$u_{i j} = 1$, при $t_j \geqslant y_i$, и $u_{i j} = 0$, при $t_j &lt; y_i$.</p>
<p>Для удобства обозначим $z_{i j} = (x_i, t_j)$.<br>
$z_{i j}$ будут лежать в области определения нашей модели, т.е. будут являться признаками, а $u_{i j}$ в области значений, т.е. будут являться таргетами.</p>
</li>
<li>
<p><strong>Новую полученную выборку лучше случайно перемешать, перед тем как приступать к обучению модели.</strong></p>
</li>
<li>
<p><strong>Строим модель обучения с учителем на обучающей выборке $\lbrace(z_{i j}, u_{i j})\rbrace$ как для обычной задачи регрессии.</strong></p>
</li>
<li>
<p><strong>Проводим валидацию модели.</strong><br>
В частности, на удовлетворение условия того, что $M(x, t)$ является функцией распределения по $t$ для каждого $x \in X$, т.е. проверяем (1), (2), (3).</p>
</li>
</ol>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="валидация"
    >
        Валидация
    </h2>
    <a data-clipboard-text="https://valmat.ru/posts/2022/09/regress-distr/#валидация" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Валидация" href="#%d0%b2%d0%b0%d0%bb%d0%b8%d0%b4%d0%b0%d1%86%d0%b8%d1%8f">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Как и для обычных задач регрессии, невозможно дать какие-то универсальные критерии оценки качества построения модели. Но можно дать несколько рекомендаций, позволяющих оценить это качество.</p>
<p>В любом случае, модель $M(x, t)$ должна быть функцией распределения по $t$ для всех $x \in X$. Если ограничения (1), (2), (3) не выполнены для $M(x, \cdot)$, то такую модель следует отвергнуть как некачественную.</p>
<p>Сам алгоритм по построению является обычной задачей регрессии. И к его результатам применимы все метрики качества, применяемые к задачам регрессии.</p>
<p>Для получения этих метрик тестовую выборку $\lbrace(x_i, y_i)\rbrace$ нужно привести к виду $\lbrace(z_{i j}, u_{i j})\rbrace$ тем же способом, что и обучающую.</p>
<p>Кроме того, мы можем перейти на уровень исходных данных и для каждой $x_i$ из тестовой выборки посчитать среднее значение $\widehat{y_i}$ как</p>
<p>$$
\widehat{y_i} = \int\limits_{t \in Y} t, dM(x_i, t)
$$</p>
<p>Таким образом, мы можем оценивать качество модели так, как если бы мы не строили распределения, а решали обычную задачу регрессии.</p>
<p>Замечу, что в некоторых случаях вместо оценки среднего $\widehat{y}$ более уместным будет оценивать наиболее вероятное значение $y$:</p>
<p>$$
\widehat{y_i} =
\arg\max \limits_{t \in Y}
\frac{\partial M(x_i, t)}{\partial t}
$$</p>
<p>В целом, подход с моделированием распределений вместо моделирования значений даёт не меньше, а даже больше способов оценки качества модели.</p>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="эксперименты"
    >
        Эксперименты
    </h2>
    <a data-clipboard-text="https://valmat.ru/posts/2022/09/regress-distr/#эксперименты" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Эксперименты" href="#%d1%8d%d0%ba%d1%81%d0%bf%d0%b5%d1%80%d0%b8%d0%bc%d0%b5%d0%bd%d1%82%d1%8b">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>В качестве базовой закономерности возьмём функцию</p>
<p>$$
f(x) = 1 - x^2 + \frac{3}{2} x - \sin(2 \pi x^2)
$$</p>
<p>на отрезке $x \in [0, 1]$.</p>
<p>Моделируем<br>
<a
  class="gblog-markdown__link"
  href="https://github.com/valmat/regress_distr/blob/master/experements.ipynb"
>Исходный код экспериментов</a>.</p>
<p>Закономерность определяется выражением выше плюс нормальный шум $\mathcal{N}(f(x), \sigma(x))$, где</p>
<p>$$
\sigma(x) = 0.05 + \frac{x}{2}
$$</p>
<p>То есть для каждой точки $x \in [0, 1]$ нашего фазового пространства значения соответствующей случайной величины, определяемой моделируемой закономерностью, распределены по закону:</p>
<p>$$
\mathcal{N}(f(x), \sigma(x))
$$</p>
<p><em>На рисунках ниже:</em></p>
<ul>
<li>(a) моделируемая закономерность</li>
<li>(b) решение обычной задачи регрессии</li>
</ul>
<p><img
  src="ex1_pic2.png"
  alt="Моделируемая закономерность и решение обычной задачи регрессии"
  
/>
<img
  src="ex1_pic4.png"
  alt="Функция распределения и плотность распределения"
  
/>
<img
  src="ex1_pic6.png"
  alt="Средние и наиболее вероятные значения, модельная функция распределения $F(x, y)$"
  
/></p>
<p>Все функции распределения для всех точек:
<img
  src="ex1_pic7.png"
  alt="Полная функция распределения"
  
/></p>
<p>Если решать обычную задачу регрессии с помощью нейронной сети, то можно увидеть, что выдаваемые моделью ответы будут довольно хорошо ложиться на средние значения, как это и ожидалось.</p>
<p>Нахождение распределений методом, описанным в настоящей статье, тоже даёт хорошие результаты.</p>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="заключение"
    >
        Заключение
    </h2>
    <a data-clipboard-text="https://valmat.ru/posts/2022/09/regress-distr/#заключение" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Заключение" href="#%d0%b7%d0%b0%d0%ba%d0%bb%d1%8e%d1%87%d0%b5%d0%bd%d0%b8%d0%b5">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>На практике, при достаточном объеме обучающей выборки, непрерывные алгоритмы машинного обучения, такие как нейронные сети, дают хорошее приближение для функций распределения.</p>
<p>В обучающей выборке могут быть образцы с близкими значениями признака $x$, но различными значениями таргета $y$. Все они вносят вклад в обучение функций распределения.</p>
<p>Эксперименты и практический опыт показывают, что ограничения, накладываемые на функцию распределения, удовлетворяются.</p>
<p>Прогнозирование распределений вместо прогнозирования средних значений даёт намного более богатые возможности для принятия решений.</p>
<p>Моделирование распределений вместо моделирования значений требует меньше дополнительных и часто невыполнимых ограничений.</p>
<p>Например, если рассмотреть решение одной и той же задачи моделированием распределений<br>
$M_{\theta}(x, t) \in [0, 1]$ и моделированием значений $R_{\theta}(x) \in \mathbb{R}$, то применение МНК, то есть MSE в качестве функции потерь, для $R_{\theta}(x)$ равносильно предположению</p>
<p>$$
M_{\theta}(x, t) \sim \mathcal{N}(t , \widehat{y}, \sigma)
$$</p>
<p>что, чаще всего, неверно.</p>
<p>Конечно, для нахождения оптимальной модели $M_{\theta_0}(x, t)$ мы тоже вынуждены сделать некоторое предположение на вид распределения ошибки $M_{\theta_0}(x, t) - \widehat{u}$  но это предположение ограничивает нас менее жёстко.</p>
<p>Платой за преимущества, даваемые моделью, предсказывающей распределения, является необходимость обучать более ёмкую модель. А следовательно, более медленная скорость сходимости по сравнению с классическим подходом.</p>
<p>Действительно, нам нужно выучить не просто среднее, но и дополнительную информацию о форме распределения.</p>
<p>Кроме того, мы вынуждены искусственно увеличить объём обучающей выборки, выполняя пополнение её таким образом, как это было описано выше.</p>
<p>Это дополнительно приводит к замедлению обучения и требует больше вычислительных ресурсов.</p>

    </section>
  </article>

      </main>

      <footer class="gblog-footer">
  <nav class="container flex">
    <div>
      <section class="flex flex-wrap align-center">
        
          <span class="gblog-footer__item gblog-footer__item--row">
            <svg class="gblog-icon gblog_rss_feed"><use xlink:href="#gblog_rss_feed"></use></svg>
            <a href="/feed.xml" class="gblog-footer__link">Atom Feed</a>
          </span>
        
        
        
        
      </section>
      <section class="flex flex-wrap align-center">
        
      </section>
      
      
    </div>
    
      <div class="flex flex-25 justify-end">
        <span class="gblog-footer__item text-right">
          <a class="gblog-footer__link fake-link" href="#" aria-label="Back to top">
            <svg class="gblog-icon gblog_keyboard_arrow_up">
              <use xlink:href="#gblog_keyboard_arrow_up"></use>
            </svg>
            <span class="hidden-mobile">Back to top</span>
          </a>
        </span>
      </div>
    
  </nav>
</footer>

    </div>
  </body>
</html>
