<!DOCTYPE html>
<html
  itemscope
  itemtype="http://schema.org/WebPage"
  lang="en"
  class="color-toggle-hidden"
  
>
  <head>
    <meta charset="UTF-8" />
<meta name="referrer" content="no-referrer" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="generator" content="Hugo 0.152.1">
  <meta name="robots" content="index, follow" />
  <meta name="description" content="Ниже представлен перевод знаменитой статьи Lost in the Middle о том, что номинальная длина контекстного окна – это совсем не то же самое, что и эффективная.
Ссылки:
PDF оригинальной статьи PDF перевода статьи Источник: https://arxiv.org/abs/2307.03172 Потерянные в середине: как языковые модели используют длинные контексты Lost in the Middle: How Language Models Use Long Contexts" />

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js" integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6" crossorigin="anonymous"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous"
  onload="renderMathInElement(document.body, {delimiters: [
  {left: '$$', right: '$$', display: true},
  {left: '$', right: '$', display: false}
]});"></script>



    <title>Lost in the Middle. Перевод знаменитой статьи | Valmat&#39;s Personal Blog</title>

    
<link rel="icon" type="image/svg+xml" href="/favicon/favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
<link rel="manifest" href="/favicon/site.webmanifest">
<link rel="mask-icon" href="/favicon/safari-pinned-tab.svg" color="#efefef">
<meta name="msapplication-TileColor" content="#efefef">
<meta name="theme-color" content="#efefef">

    

    
  <meta
    property="og:title"
    content="Lost in the Middle. Перевод знаменитой статьи"
  />
  <meta property="og:site_name" content="Valmat's Personal Blog" />
  <meta property="og:description" content="Ниже представлен перевод знаменитой статьи Lost in the Middle о том, что номинальная длина контекстного окна – это совсем не то же самое, что и эффективная.
Ссылки:
PDF оригинальной статьи PDF перевода статьи Источник: https://arxiv.org/abs/2307.03172 Потерянные в середине: как языковые модели используют длинные контексты Lost in the Middle: How Language Models Use Long Contexts" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://valmat.ru/posts/2025/08/lost-in-the-middle/" />

<meta property="article:section" content="Posts" />
    <meta
      property="article:published_time"
      content="2025-08-30T22:38:23+03:00"
    />
    <meta
      property="article:modified_time"
      content="2025-08-30T22:38:23+03:00"
    />


  <meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Lost in the Middle. Перевод знаменитой статьи" />
  <meta name="twitter:description" content="Ниже представлен перевод знаменитой статьи Lost in the Middle о том, что номинальная длина контекстного окна – это совсем не то же самое, что и эффективная.
Ссылки:
PDF оригинальной статьи PDF перевода статьи Источник: https://arxiv.org/abs/2307.03172 Потерянные в середине: как языковые модели используют длинные контексты Lost in the Middle: How Language Models Use Long Contexts" />

<script type="application/ld+json">
  {
      "@context": "http://schema.org",
      "@type": "BlogPosting",
      "articleSection": "Posts",
      "name": "Lost in the Middle. Перевод знаменитой статьи",
      "url" : "https://valmat.ru/posts/2025/08/lost-in-the-middle/",
      "headline": "Lost in the Middle. Перевод знаменитой статьи",
      "description": "Ниже представлен перевод знаменитой статьи Lost in the Middle о том, что номинальная длина контекстного окна – это совсем не то же самое, что и эффективная.\nСсылки:\nPDF оригинальной статьи PDF перевода статьи Источник: https:\/\/arxiv.org\/abs\/2307.03172 Потерянные в середине: как языковые модели используют длинные контексты Lost in the Middle: How Language Models Use Long Contexts",
      "wordCount" : "2630",
      "inLanguage": "en",
      "isFamilyFriendly": "true",
      "mainEntityOfPage": {
          "@type": "WebPage",
          "@id": "https://valmat.ru/posts/2025/08/lost-in-the-middle/"
      },
      "keywords" : [ "LLM" ],
      "author" : [
      ],
      "copyrightHolder" : "Valmat\u0027s Personal Blog",
      "copyrightYear" : "2025",
      "dateCreated": "2025-08-30T22:38:23.00Z",
      "datePublished": "2025-08-30T22:38:23.00Z",
      "dateModified": "2025-08-30T22:38:23.00Z",
      "publisher":{
          "@type":"Organization",
          "name": "Valmat's Personal Blog",
          "url": "https://valmat.ru/",
          "logo": {
              "@type": "ImageObject",
              "url": "https://valmat.ru/brand.svg",
              "width":"32",
              "height":"32"
          }
      }
  }
  </script>


    
  <script src="/js/colortheme-c15a9bc4.bundle.min.js"></script>
<script src="/js/main-de0fc7bf.bundle.min.js"></script>

<link
  rel="preload"
  as="font"
  href="/fonts/Metropolis.woff2"
  type="font/woff2"
  crossorigin="anonymous"
/>
<link
  rel="preload"
  as="font"
  href="/fonts/LiberationSans.woff2"
  type="font/woff2"
  crossorigin="anonymous"
/>
<link
  rel="preload"
  as="font"
  href="/fonts/GeekblogIcons.woff2"
  type="font/woff2"
  crossorigin="anonymous"
/>

<link
  rel="preload"
  href="/main-d8f6de16.min.css"
  as="style"
/>
<link
  rel="stylesheet"
  href="/main-d8f6de16.min.css"
  media="all"
/>

<link
  rel="preload"
  href="/mobile-7fcdde51.min.css"
  as="style"
/>
<link
  rel="stylesheet"
  href="/mobile-7fcdde51.min.css"
  media="screen and (max-width: 45rem)"
/>

<link
  rel="preload"
  href="/print-cc34f864.min.css"
  as="style"
/>
<link
  rel="stylesheet"
  href="/print-cc34f864.min.css"
  media="print"
/>

<link
  rel="preload"
  href="/custom.css"
  as="style"
/>
<link
  rel="stylesheet"
  href="/custom.css"
  media="all"
/>
  <link href="https://valmat.ru/posts/2025/08/lost-in-the-middle/" rel="canonical" type="text/html" />
    <link href="https://valmat.ru/feed.xml" rel="alternate" type="application/atom+xml" title="Valmat's Personal Blog atom Feed" />

<!-- Made with Geekblog theme https://github.com/thegeeklab/hugo-geekblog -->

    

  </head>

  <body>
    
  <!-- geekblog include: /sprites/geekblog.svg -->
  <svg class="svg-sprite" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_arrow_back" xmlns="http://www.w3.org/2000/svg"><path d="M31.999 14.035v3.93H7.673l11.134 11.228L16 32 .001 16.001 16 .002l2.807 2.807L7.673 14.037h24.326z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_arrow_left" xmlns="http://www.w3.org/2000/svg"><path d="M7.954 17.965v5.988L.001 16l7.953-7.953v5.988H32v3.93H7.954z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_arrow_right" xmlns="http://www.w3.org/2000/svg"><path d="M24.046 14.035V8.047L31.999 16l-7.953 7.953v-5.988H0v-3.93h24.046z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_bitbucket" xmlns="http://www.w3.org/2000/svg"><path d="M15.905 13.355c.189 1.444-1.564 2.578-2.784 1.839-1.375-.602-1.375-2.784-.034-3.403 1.151-.705 2.818.223 2.818 1.564zm1.907-.361c-.309-2.44-3.076-4.056-5.328-3.042-1.426.636-2.389 2.148-2.32 3.747.086 2.097 2.08 3.815 4.176 3.626s3.729-2.234 3.472-4.331zm4.108-9.315c-.756-.997-2.045-1.169-3.179-1.358-3.214-.516-6.513-.533-9.727.034-1.066.172-2.269.361-2.939 1.323 1.1 1.031 2.664 1.186 4.073 1.358 2.544.327 5.156.344 7.699.017 1.426-.172 3.008-.309 4.073-1.375zm.979 17.788c-.481 1.684-.206 3.953-1.994 4.932-3.076 1.701-6.806 1.89-10.191 1.289-1.787-.327-3.884-.894-4.864-2.578-.43-1.65-.705-3.334-.98-5.018l.103-.275.309-.155c5.121 3.386 12.288 3.386 17.427 0 .808.241.206 1.22.189 1.805zM26.01 4.951c-.584 3.764-1.255 7.51-1.908 11.257-.189 1.1-1.255 1.719-2.148 2.183-3.214 1.615-6.96 1.89-10.483 1.512-2.389-.258-4.829-.894-6.771-2.389-.911-.705-.911-1.908-1.083-2.922-.602-3.523-1.289-7.046-1.719-10.604.206-1.547 1.942-2.217 3.231-2.698C6.848.654 8.686.362 10.508.19c3.884-.378 7.854-.241 11.618.859 1.341.395 2.784.945 3.695 2.097.412.533.275 1.203.189 1.805z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_bookmark" xmlns="http://www.w3.org/2000/svg"><path d="M20.357 5.856q1.157 0 2.043.851t.885 2.008v23.284l-10.212-4.357-10.144 4.357V8.715q0-1.157.885-2.008t2.042-.851h14.502zm5.787 18.859V5.856q0-1.157-.851-2.042t-2.008-.885H8.715q0-1.157.885-2.042t2.043-.885h14.502q1.157 0 2.043.885t.885 2.042v23.216z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_brightness_auto" xmlns="http://www.w3.org/2000/svg"><path d="M16.846 18.938h2.382L15.22 7.785h-2.44L8.772 18.938h2.382l.871-2.44h3.95zm7.087-9.062L27.999 14l-4.066 4.124v5.809h-5.809L14 27.999l-4.124-4.066H4.067v-5.809L.001 14l4.066-4.124V4.067h5.809L14 .001l4.124 4.066h5.809v5.809zm-11.385 4.937L14 10.282l1.452 4.531h-2.904z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_brightness_dark" xmlns="http://www.w3.org/2000/svg"><path d="M14 21.435q3.079 0 5.257-2.178T21.435 14t-2.178-5.257T14 6.565q-1.51 0-3.079.697 1.917.871 3.108 2.701T15.22 14t-1.191 4.037-3.108 2.701q1.568.697 3.079.697zm9.933-11.559L27.999 14l-4.066 4.124v5.809h-5.809L14 27.999l-4.124-4.066H4.067v-5.809L.001 14l4.066-4.124V4.067h5.809L14 .001l4.124 4.066h5.809v5.809z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_brightness_light" xmlns="http://www.w3.org/2000/svg"><path d="M14 21.435q3.079 0 5.257-2.178T21.435 14t-2.178-5.257T14 6.565 8.743 8.743 6.565 14t2.178 5.257T14 21.435zm9.933-3.311v5.809h-5.809L14 27.999l-4.124-4.066H4.067v-5.809L.001 14l4.066-4.124V4.067h5.809L14 .001l4.124 4.066h5.809v5.809L27.999 14z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_check" xmlns="http://www.w3.org/2000/svg"><path d="M8.885 20.197 25.759 3.323l2.24 2.24L8.885 24.677 0 15.792l2.24-2.24z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_check_circle_outline" xmlns="http://www.w3.org/2000/svg"><path d="M14 25.239q4.601 0 7.92-3.319T25.239 14 21.92 6.08 14 2.761 6.08 6.08 2.761 14t3.319 7.92T14 25.239zM14 0q5.784 0 9.892 4.108T28 14t-4.108 9.892T14 28t-9.892-4.108T0 14t4.108-9.892T14 0zm6.441 7.822 1.972 1.972-11.239 11.239L4.207 14l1.972-1.972 4.995 4.995z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_clear" xmlns="http://www.w3.org/2000/svg"><path d="M32 3.222 19.222 16 32 28.778l-3.221 3.221-12.778-12.778L3.223 31.999.002 28.778 12.78 16 .002 3.222 3.223.001l12.778 12.778L28.779.001z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_cloud_off" xmlns="http://www.w3.org/2000/svg"><path d="M9.023 10.5H7q-1.914 0-3.281 1.395t-1.367 3.309 1.367 3.281T7 19.852h11.375zM3.5 4.976l1.477-1.477L24.5 23.022l-1.477 1.477-2.352-2.297H6.999q-2.898 0-4.949-2.051t-2.051-4.949q0-2.844 1.969-4.867t4.758-2.133zm19.086 5.578q2.242.164 3.828 1.832T28 16.351q0 3.008-2.461 4.758l-1.695-1.695q1.805-.984 1.805-3.063 0-1.422-1.039-2.461t-2.461-1.039h-1.75v-.602q0-2.68-1.859-4.539t-4.539-1.859q-1.531 0-2.953.711l-1.75-1.695Q11.431 3.5 14.001 3.5q2.953 0 5.496 2.078t3.09 4.977z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_code" xmlns="http://www.w3.org/2000/svg"><path d="M9.917 24.5a1.75 1.75 0 1 0-3.501.001 1.75 1.75 0 0 0 3.501-.001zm0-21a1.75 1.75 0 1 0-3.501.001A1.75 1.75 0 0 0 9.917 3.5zm11.666 2.333a1.75 1.75 0 1 0-3.501.001 1.75 1.75 0 0 0 3.501-.001zm1.75 0a3.502 3.502 0 0 1-1.75 3.026c-.055 6.581-4.721 8.039-7.82 9.023-2.898.911-3.846 1.349-3.846 3.117v.474a3.502 3.502 0 0 1 1.75 3.026c0 1.932-1.568 3.5-3.5 3.5s-3.5-1.568-3.5-3.5c0-1.294.711-2.424 1.75-3.026V6.526A3.502 3.502 0 0 1 4.667 3.5c0-1.932 1.568-3.5 3.5-3.5s3.5 1.568 3.5 3.5a3.502 3.502 0 0 1-1.75 3.026v9.06c.93-.456 1.914-.766 2.807-1.039 3.391-1.075 5.323-1.878 5.359-5.687a3.502 3.502 0 0 1-1.75-3.026c0-1.932 1.568-3.5 3.5-3.5s3.5 1.568 3.5 3.5z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_contacts" xmlns="http://www.w3.org/2000/svg"><path d="M22.688 22.688v-2q0-1.5-2.281-2.438t-4.406-.938-4.406.938-2.281 2.438v2h13.375zM16 9q-1.25 0-2.125.875T13 12t.875 2.125T16 15t2.125-.875T19 12t-.875-2.125T16 9zm10.688-3.687q1.063 0 1.844.813t.781 1.875v16q0 1.063-.781 1.875t-1.844.813H5.313q-1.063 0-1.844-.813t-.781-1.875v-16q0-1.063.781-1.875t1.844-.813h21.375zM5.313 32v-2.688h21.375V32H5.313zM26.688 0v2.688H5.313V0h21.375z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_copy" xmlns="http://www.w3.org/2000/svg"><path d="M23.502 25.438V7.626H9.562v17.812h13.94zm0-20.315q1.013 0 1.787.745t.774 1.757v17.812q0 1.013-.774 1.787t-1.787.774H9.562q-1.013 0-1.787-.774t-.774-1.787V7.625q0-1.013.774-1.757t1.787-.745h13.94zM19.689 0v2.562H4.438v17.812H1.936V2.562q0-1.013.745-1.787T4.438.001h15.251z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_create" xmlns="http://www.w3.org/2000/svg"><path d="m31.499 7.167-3.25 3.25-6.666-6.666 3.25-3.25q.5-.5 1.25-.5t1.25.5l4.166 4.166q.5.5.5 1.25t-.5 1.25zM.001 25.333 19.667 5.667l6.666 6.666L6.667 31.999H.001v-6.666z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_dangerous" xmlns="http://www.w3.org/2000/svg"><path d="M21.802 19.833 15.969 14l5.833-5.833-1.969-1.969L14 12.031 8.167 6.198 6.198 8.167 12.031 14l-5.833 5.833 1.969 1.969L14 15.969l5.833 5.833zM19.833 0 28 8.167v11.666L19.833 28H8.167L0 19.833V8.167L8.167 0h11.666z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_date" xmlns="http://www.w3.org/2000/svg"><path d="M27.192 28.844V11.192H4.808v17.652h22.384zm0-25.689q1.277 0 2.253.976t.976 2.253v22.459q0 1.277-.976 2.216t-2.253.939H4.808q-1.352 0-2.291-.901t-.939-2.253V6.385q0-1.277.939-2.253t2.291-.976h1.577V.001h3.23v3.155h12.769V.001h3.23v3.155h1.577zm-3.155 11.267v3.155h-3.23v-3.155h3.23zm-6.46 0v3.155h-3.155v-3.155h3.155zm-6.384 0v3.155h-3.23v-3.155h3.23z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_download" xmlns="http://www.w3.org/2000/svg"><path d="M2.866 28.209h26.269v3.79H2.866v-3.79zm26.268-16.925L16 24.418 2.866 11.284h7.493V.001h11.283v11.283h7.493z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_email" xmlns="http://www.w3.org/2000/svg"><path d="M28.845 9.615v-3.23L16 14.422 3.155 6.385v3.23L16 17.577zm0-6.46q1.277 0 2.216.977T32 6.385v19.23q0 1.277-.939 2.253t-2.216.977H3.155q-1.277 0-2.216-.977T0 25.615V6.385q0-1.277.939-2.253t2.216-.977h25.69z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_error_outline" xmlns="http://www.w3.org/2000/svg"><path d="M14 25.239q4.601 0 7.92-3.319T25.239 14 21.92 6.08 14 2.761 6.08 6.08 2.761 14t3.319 7.92T14 25.239zM14 0q5.784 0 9.892 4.108T28 14t-4.108 9.892T14 28t-9.892-4.108T0 14t4.108-9.892T14 0zm-1.38 6.967h2.761v8.413H12.62V6.967zm0 11.239h2.761v2.826H12.62v-2.826z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_fire" xmlns="http://www.w3.org/2000/svg"><path d="M17.689 21.998q-.32.32-.8.576t-.864.384q-1.152.384-2.272.032t-1.888-.992q-.128-.128-.096-.256t.16-.192q1.216-.384 1.92-1.216t.96-1.792q.192-.896-.064-1.728t-.384-1.728q-.128-.704-.096-1.376t.288-1.312q0-.128.128-.128t.192.064q.384.832.992 1.472t1.28 1.216 1.216 1.248.672 1.568q.064.384.064.704.064.96-.32 1.92t-1.088 1.536zm3.84-10.944q-.768-.704-1.6-1.28t-1.6-1.344q-1.536-1.536-2.016-3.584t.16-4.16q.128-.32-.096-.544t-.544-.096q-.768.32-1.44.768t-1.312.896q-1.984 1.664-3.136 3.936T8.633 10.51t.8 5.088q0 .128.032.256t.032.256q0 .576-.512.832t-1.024-.192q-.128-.192-.192-.32-1.024-1.28-1.376-2.912t-.096-3.232q.064-.384-.288-.576t-.608.128q-1.28 1.664-1.856 3.68t-.448 4.064q0 .576.096 1.184t.288 1.184q.448 1.536 1.216 2.816 1.216 2.048 3.264 3.424t4.416 1.696q2.496.32 5.024-.256t4.448-2.304q1.408-1.344 2.208-3.104t.864-3.68-.704-3.712q-.064-.128-.096-.224t-.096-.224q-.576-1.088-1.28-1.984-.256-.384-.544-.704t-.672-.64z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_git" xmlns="http://www.w3.org/2000/svg"><path d="M27.472 12.753 15.247.529a1.803 1.803 0 0 0-2.55 0l-2.84 2.84 2.137 2.137a2.625 2.625 0 0 1 3.501 3.501l3.499 3.499a2.625 2.625 0 1 1-1.237 1.237l-3.499-3.499c-.083.04-.169.075-.257.106v7.3a2.626 2.626 0 1 1-1.75 0v-7.3a2.626 2.626 0 0 1-1.494-3.607L8.62 4.606l-8.09 8.09a1.805 1.805 0 0 0 0 2.551l12.225 12.224a1.803 1.803 0 0 0 2.55 0l12.168-12.168a1.805 1.805 0 0 0 0-2.551z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_gitea" xmlns="http://www.w3.org/2000/svg"><path d="M5.581 7.229c-2.46-.005-5.755 1.559-5.573 5.48.284 6.125 6.56 6.693 9.068 6.743.275 1.149 3.227 5.112 5.412 5.32h9.573c5.741-.381 10.04-17.363 6.853-17.427-5.271.248-8.395.373-11.073.395v5.3l-.835-.369-.005-4.928c-3.075-.001-5.781-.144-10.919-.397-.643-.004-1.539-.113-2.501-.116zm.348 2.166h.293c.349 3.14.917 4.976 2.067 7.781-2.933-.347-5.429-1.199-5.888-4.38-.237-1.647.563-3.365 3.528-3.401zm11.409 3.087c.2.003.404.04.596.128l.999.431-.716 1.305h-.007a.996.996 0 0 0-.321.053l.006-.002c-.349.114-.593.406-.593.749 0 .097.019.189.055.275l-.002-.006a.767.767 0 0 0 .151.233l-.001-.001-1.235 2.248a.99.99 0 0 0-.302.052l.006-.002c-.349.114-.593.406-.593.749 0 .097.019.189.055.275l-.002-.006c.128.31.457.527.843.527a.987.987 0 0 0 .31-.049l-.006.002c.348-.114.592-.406.592-.749 0-.097-.02-.19-.056-.277l.002.006a.784.784 0 0 0-.211-.293l1.203-2.189a.999.999 0 0 0 .397-.041l-.006.002a.942.942 0 0 0 .285-.15l-.001.001c.464.195.844.353 1.117.488.411.203.556.337.6.487.044.147-.004.429-.236.925-.173.369-.46.893-.799 1.511h-.02a.991.991 0 0 0-.321.053l.006-.002c-.349.114-.593.406-.593.749 0 .097.019.189.055.275l-.002-.006c.128.31.457.527.843.527a.987.987 0 0 0 .31-.049l-.006.002c.348-.114.592-.406.592-.749a.703.703 0 0 0-.055-.275l.002.006a.802.802 0 0 0-.183-.27l.001.001c.335-.611.623-1.136.808-1.531.251-.536.381-.935.267-1.32s-.467-.636-.933-.867c-.307-.151-.689-.311-1.147-.503a.723.723 0 0 0-.052-.324l.002.006a.792.792 0 0 0-.194-.279l.704-1.284 3.899 1.684c.704.305.995 1.053.653 1.68l-2.68 4.907c-.343.625-1.184.884-1.888.58l-5.516-2.384c-.704-.304-.996-1.053-.653-1.68l2.68-4.905c.235-.431.707-.687 1.207-.707z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_github" xmlns="http://www.w3.org/2000/svg"><path d="M16 .394c8.833 0 15.999 7.166 15.999 15.999 0 7.062-4.583 13.062-10.937 15.187-.813.146-1.104-.354-1.104-.771 0-.521.021-2.25.021-4.396 0-1.5-.5-2.458-1.083-2.958 3.562-.396 7.312-1.75 7.312-7.896 0-1.75-.625-3.167-1.646-4.291.167-.417.708-2.042-.167-4.25-1.333-.417-4.396 1.646-4.396 1.646a15.032 15.032 0 0 0-8 0S8.937 6.602 7.603 7.018c-.875 2.208-.333 3.833-.167 4.25-1.021 1.125-1.646 2.542-1.646 4.291 0 6.125 3.729 7.5 7.291 7.896-.458.417-.875 1.125-1.021 2.146-.917.417-3.25 1.125-4.646-1.333-.875-1.521-2.458-1.646-2.458-1.646-1.562-.021-.104.979-.104.979 1.042.479 1.771 2.333 1.771 2.333.938 2.854 5.396 1.896 5.396 1.896 0 1.333.021 2.583.021 2.979 0 .417-.292.917-1.104.771C4.582 29.455-.001 23.455-.001 16.393-.001 7.56 7.165.394 15.998.394zM6.063 23.372c.042-.083-.021-.187-.146-.25-.125-.042-.229-.021-.271.042-.042.083.021.187.146.25.104.062.229.042.271-.042zm.646.709c.083-.062.062-.208-.042-.333-.104-.104-.25-.146-.333-.062-.083.062-.062.208.042.333.104.104.25.146.333.062zm.625.937c.104-.083.104-.25 0-.396-.083-.146-.25-.208-.354-.125-.104.062-.104.229 0 .375s.271.208.354.146zm.875.875c.083-.083.042-.271-.083-.396-.146-.146-.333-.167-.417-.062-.104.083-.062.271.083.396.146.146.333.167.417.062zm1.187.521c.042-.125-.083-.271-.271-.333-.167-.042-.354.021-.396.146s.083.271.271.312c.167.062.354 0 .396-.125zm1.313.104c0-.146-.167-.25-.354-.229-.187 0-.333.104-.333.229 0 .146.146.25.354.229.187 0 .333-.104.333-.229zm1.208-.208c-.021-.125-.187-.208-.375-.187-.187.042-.312.167-.292.312.021.125.187.208.375.167s.312-.167.292-.292z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_gitlab" xmlns="http://www.w3.org/2000/svg"><path d="M1.629 11.034 14 26.888.442 17.048a1.09 1.09 0 0 1-.39-1.203l1.578-4.811zm7.217 0h10.309l-5.154 15.854zM5.753 1.475l3.093 9.559H1.63l3.093-9.559a.548.548 0 0 1 1.031 0zm20.618 9.559 1.578 4.811c.141.437-.016.922-.39 1.203l-13.558 9.84 12.371-15.854zm0 0h-7.216l3.093-9.559a.548.548 0 0 1 1.031 0z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_heart" xmlns="http://www.w3.org/2000/svg"><path d="M16 29.714a1.11 1.11 0 0 1-.786-.321L4.072 18.643c-.143-.125-4.071-3.714-4.071-8 0-5.232 3.196-8.357 8.535-8.357 3.125 0 6.053 2.464 7.464 3.857 1.411-1.393 4.339-3.857 7.464-3.857 5.339 0 8.535 3.125 8.535 8.357 0 4.286-3.928 7.875-4.089 8.035L16.785 29.392c-.214.214-.5.321-.786.321z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_info_outline" xmlns="http://www.w3.org/2000/svg"><path d="M12.62 9.793V6.967h2.761v2.826H12.62zM14 25.239q4.601 0 7.92-3.319T25.239 14 21.92 6.08 14 2.761 6.08 6.08 2.761 14t3.319 7.92T14 25.239zM14 0q5.784 0 9.892 4.108T28 14t-4.108 9.892T14 28t-9.892-4.108T0 14t4.108-9.892T14 0zm-1.38 21.033V12.62h2.761v8.413H12.62z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_keyboard_arrow_down" xmlns="http://www.w3.org/2000/svg"><path d="M3.281 5.36 14 16.079 24.719 5.36 28 8.641l-14 14-14-14z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_keyboard_arrow_left" xmlns="http://www.w3.org/2000/svg"><path d="M25.875 28.25 22.125 32 6.126 16.001 22.125.002l3.75 3.75-12.25 12.25z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_keyboard_arrow_right" xmlns="http://www.w3.org/2000/svg"><path d="M6.125 28.25 18.375 16 6.125 3.75 9.875 0l15.999 15.999L9.875 31.998z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_keyboard_arrow_up" xmlns="http://www.w3.org/2000/svg"><path d="M24.719 22.64 14 11.921 3.281 22.64 0 19.359l14-14 14 14z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_link" xmlns="http://www.w3.org/2000/svg"><path d="M24.037 7.963q3.305 0 5.634 2.366T32 16t-2.329 5.671-5.634 2.366h-6.46v-3.08h6.46q2.028 0 3.493-1.465t1.465-3.493-1.465-3.493-3.493-1.465h-6.46v-3.08h6.46zM9.615 17.578v-3.155h12.77v3.155H9.615zM3.005 16q0 2.028 1.465 3.493t3.493 1.465h6.46v3.08h-6.46q-3.305 0-5.634-2.366T0 16.001t2.329-5.671 5.634-2.366h6.46v3.08h-6.46q-2.028 0-3.493 1.465t-1.465 3.493z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_mastodon" xmlns="http://www.w3.org/2000/svg"><path d="M30.924 10.506c0-6.941-4.548-8.976-4.548-8.976C24.083.477 20.144.034 16.054.001h-.101C11.862.034 7.926.477 5.633 1.53c0 0-4.548 2.035-4.548 8.976 0 1.589-.031 3.491.02 5.505.165 6.79 1.245 13.479 7.522 15.14 2.893.765 5.379.927 7.38.816 3.629-.2 5.667-1.296 5.667-1.296l-.12-2.633s-2.593.817-5.505.719c-2.887-.099-5.932-.311-6.399-3.855a7.069 7.069 0 0 1-.064-.967v-.028.001s2.833.693 6.423.857c2.195.1 4.253-.129 6.344-.377 4.009-.479 7.5-2.949 7.939-5.207.689-3.553.633-8.676.633-8.676zm-5.366 8.945h-3.329v-8.159c0-1.72-.724-2.592-2.171-2.592-1.6 0-2.403 1.035-2.403 3.083v4.465h-3.311v-4.467c0-2.048-.803-3.083-2.403-3.083-1.447 0-2.171.873-2.171 2.592v8.159H6.441v-8.404c0-1.719.437-3.084 1.316-4.093.907-1.011 2.092-1.528 3.565-1.528 1.704 0 2.995.655 3.848 1.965l.828 1.391.829-1.391c.853-1.311 2.144-1.965 3.848-1.965 1.472 0 2.659.517 3.565 1.528.877 1.009 1.315 2.375 1.315 4.093z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_matrix" xmlns="http://www.w3.org/2000/svg"><path d="M.843.734v30.532H3.04v.733H0V0h3.04v.733zm9.391 9.68v1.543h.044a4.417 4.417 0 0 1 1.489-1.365c.577-.327 1.248-.487 2-.487.72 0 1.377.143 1.975.419.597.277 1.047.776 1.36 1.477.339-.499.8-.941 1.379-1.323.579-.383 1.267-.573 2.061-.573.604 0 1.163.075 1.68.223a3.34 3.34 0 0 1 1.324.707c.368.327.652.745.861 1.268.203.523.307 1.151.307 1.889v7.637h-3.132v-6.468c0-.381-.013-.745-.043-1.083a2.315 2.315 0 0 0-.246-.893l.006.013a1.484 1.484 0 0 0-.577-.593l-.007-.004c-.259-.147-.609-.221-1.047-.221-.443 0-.8.085-1.071.252-.267.166-.483.39-.635.656l-.005.009a2.558 2.558 0 0 0-.307.915l-.002.013a7.156 7.156 0 0 0-.08 1.044v6.359h-3.133v-6.4c0-.339-.005-.671-.024-1.003a2.772 2.772 0 0 0-.197-.936l.007.019a1.41 1.41 0 0 0-.548-.667l-.006-.003c-.259-.167-.635-.253-1.139-.253-.148 0-.345.032-.585.099-.24.068-.48.191-.707.376-.228.184-.425.449-.585.793-.16.345-.24.8-.24 1.36v6.621H7.279v-11.42zm20.923 20.852V.734H28.96V.001H32V32h-3.04v-.733z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_menu" xmlns="http://www.w3.org/2000/svg"><path d="M.001 5.334h31.998v3.583H.001V5.334zm0 12.416v-3.5h31.998v3.5H.001zm0 8.916v-3.583h31.998v3.583H.001z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_notifications" xmlns="http://www.w3.org/2000/svg"><path d="m25.846 22.154 3.308 3.308v1.615H2.847v-1.615l3.308-3.308V14q0-3.846 1.961-6.692t5.423-3.692V2.462q0-1 .692-1.731T16 0t1.769.731.692 1.731v1.154q3.461.846 5.423 3.692T25.846 14v8.154zM16 32q-1.385 0-2.346-.923t-.962-2.308h6.615q0 1.308-1 2.269T15.999 32z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_person" xmlns="http://www.w3.org/2000/svg"><path d="M16 20.023q5.052 0 10.526 2.199t5.473 5.754v4.023H0v-4.023q0-3.555 5.473-5.754t10.526-2.199zM16 16q-3.275 0-5.614-2.339T8.047 8.047t2.339-5.661T16 0t5.614 2.386 2.339 5.661-2.339 5.614T16 16z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_pin" xmlns="http://www.w3.org/2000/svg"><path d="M17.6 19.2h9.6v-1.6L22.4 16V3.2l4.8-1.6V0H4.8v1.6l4.8 1.6V16l-4.8 1.6v1.6h9.6v11.2L16 32l1.6-1.6V19.2z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_rss_feed" xmlns="http://www.w3.org/2000/svg"><path d="M-.481 12.048q8.482 0 14.457 5.976t5.976 14.457h-5.879q0-5.976-4.289-10.264T-.48 17.928v-5.879zm0-11.565q13.204 0 22.601 9.397t9.397 22.601h-5.783q0-10.891-7.662-18.553T-.481 6.266V.483zm0 27.468q0-1.831 1.301-3.132t3.229-1.301 3.181 1.253 1.253 3.181-1.301 3.229-3.132 1.301q-1.928 0-3.229-1.301T-.48 27.952z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_search" xmlns="http://www.w3.org/2000/svg"><path d="M11.925 20.161q3.432 0 5.834-2.402t2.402-5.834-2.402-5.834-5.834-2.402-5.834 2.402-2.402 5.834 2.402 5.834 5.834 2.402zm10.981 0L32 29.255 29.255 32l-9.094-9.094v-1.458l-.515-.515q-3.26 2.831-7.721 2.831-4.976 0-8.45-3.432T.001 11.925t3.474-8.45 8.45-3.474 8.407 3.474 3.432 8.45q0 1.802-.858 4.075t-1.973 3.646l.515.515h1.458z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_security" xmlns="http://www.w3.org/2000/svg"><path d="m16 0 13.072 5.855v8.715q0 6.059-3.745 11.063T16 31.999q-5.583-1.362-9.327-6.366T2.928 14.57V5.855zm0 16v13.004q4.017-1.294 6.808-4.868T26.144 16H16zm0 0V3.2L5.856 7.693v8.306H16z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_star" xmlns="http://www.w3.org/2000/svg"><path d="M14 22.052 5.324 27.31l2.3-9.859L0 10.813l10.056-.854L14 .692l3.944 9.267L28 10.813l-7.624 6.638 2.3 9.859z"/></svg><svg viewBox="-7.27 -7.27 42.55 42.55" id="gblog_tag" xmlns="http://www.w3.org/2000/svg"><path d="M17.52 17.52v-7.041h-7.041v7.041h7.041zM28 10.479h-7.041v7.041H28v3.439h-7.041V28H17.52v-7.041h-7.041V28H7.04v-7.041H-.001V17.52H7.04v-7.041H-.001V7.04H7.04V-.001h3.439V7.04h7.041V-.001h3.439V7.04H28v3.439z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_timer" xmlns="http://www.w3.org/2000/svg"><path d="M16 29q4.428 0 7.536-3.143t3.107-7.571-3.107-7.536T16 7.643 8.464 10.75t-3.107 7.536 3.107 7.571T16 29zM26.714 9.786q1.214 1.571 2.107 4.036t.893 4.464q0 5.643-4 9.678T16 32t-9.714-4.036-4-9.678 4-9.678T16 4.572q1.929 0 4.464.929t4.107 2.143l2.143-2.214q1.143.929 2.143 2.143zM14.5 19.857v-9.143h3v9.143h-3zM20.571.001v3.071h-9.143V.001h9.143z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_tree" xmlns="http://www.w3.org/2000/svg"><path d="M32 14.423H20.808V9.616h-3.23v12.77h3.23v-4.807H32v12.845H20.808v-4.807h-6.385v-16h-3.23v4.807H.001V1.579h11.192v4.807h9.615V1.579H32v12.845z"/></svg><svg viewBox="-7.27 -7.27 46.55 46.55" id="gblog_xmpp" xmlns="http://www.w3.org/2000/svg"><path d="M31.995 4.237c-.449.175-1.12.433-1.936.745-1.544.591-2.328.891-2.924 1.093-.613.208-1.287.409-2.635.813-.911.272-1.672.495-2.212.651-.031.875 0 2.177-.292 3.635a21.837 21.837 0 0 1-2.016 5.765c-1.496 2.944-3.236 4.817-3.88 5.476-.056-.059-.112-.117-.168-.179-.707-.763-2.403-2.703-3.815-5.683-1.053-2.223-1.484-4.044-1.605-4.584-.356-1.589-.427-2.955-.427-4.117 0-.075-.036-.129-.101-.149-.721-.223-1.765-.519-2.887-.853-1.271-.379-2.193-.744-3.408-1.2-.493-.185-1.409-.547-2.217-.859C.723 4.499.113 4.236.041 4.236c-.005 0-.015 0-.023.012a.131.131 0 0 0-.019.076c.009.593.08 1.361.256 2.365.615 3.503 2.688 7.061 4.36 9.244 0 0 3.717 5.035 9.128 8.144l.303.176c-.009.008-.02.015-.028.021-1.717 1.316-3.201 1.977-3.579 2.14a15.71 15.71 0 0 1-2.219.772v.407a25.31 25.31 0 0 0 2.72-.487 26.72 26.72 0 0 0 5.075-1.792c.136.067.276.136.42.204 1.527.725 3.571 1.627 6.073 2.048.613.103 1.136.165 1.507.195a.109.109 0 0 0 .115-.091.55.55 0 0 0 .004-.217.107.107 0 0 0-.063-.073c-.505-.209-1.201-.4-1.983-.719-.935-.381-2.241-1.067-3.648-2.128a13.528 13.528 0 0 1-.367-.287c4.64-2.656 7.989-6.588 7.989-6.588 1.735-2.036 4.441-5.623 5.431-9.795.349-1.473.539-2.741.5-3.628z"/></svg></defs></svg>




    <div
      class="wrapper "
    >
      <header class="gblog-header">
  <div class="container flex flex-wrap">
    <div class="gblog-header__col-1 flex justify-start hidden-mobile"></div>
    <div class="gblog-header__col-2 flex align-center justify-center ">
      <a class="gblog-header__link" rel="me" href="https://valmat.ru/">
        <span class="gblog-brand flex align-center justify-center">
          
          <span class="gblog-brand__title">Valmat&#39;s Personal Blog</span>
        </span>
        
      </a>
    </div>
    <div class="gblog-header__col-3 flex justify-end">
      <span id="gblog-color-theme">
        <svg class="gblog-icon gblog_brightness_dark">
          <title>Toggle Dark/Light/Auto mode</title>
          <use xlink:href="#gblog_brightness_dark"></use>
        </svg>
        <svg class="gblog-icon gblog_brightness_light">
          <title>Toggle Dark/Light/Auto mode</title>
          <use xlink:href="#gblog_brightness_light"></use>
        </svg>
        <svg class="gblog-icon gblog_brightness_auto">
          <title>Toggle Dark/Light/Auto mode</title>
          <use xlink:href="#gblog_brightness_auto"></use>
        </svg>
      </span>
    </div>
  </div>
</header>
<nav class="gblog-nav">
  <input type="checkbox" id="menu-control" class="hidden" />
  <div class="gblog-nav__control">
    <label for="menu-control" class="flex align-center justify-center">
      <svg class="gblog-icon gblog_menu"><use xlink:href="#gblog_menu"></use></svg>
      <svg class="gblog-icon gblog_clear"><use xlink:href="#gblog_clear"></use></svg>
      <span>Navigation</span>
    </label>
  </div>
  <ul class="gblog-nav__list container flex flex-wrap justify-center menu-content">
    
    
      
        
          <li>
            <a
              class="gblog-nav__entry"
              href="/tags/AI/"
            >
              Ai
            </a>
          </li>
        
      
        
          <li>
            <a
              class="gblog-nav__entry"
              href="/tags/algo/"
            >
              Algo
            </a>
          </li>
        
      
        
          <li>
            <a
              class="gblog-nav__entry"
              href="/tags/archive/"
            >
              Archive
            </a>
          </li>
        
      
        
          <li>
            <a
              class="gblog-nav__entry"
              href="/tags/cpp/"
            >
              Cpp
            </a>
          </li>
        
      
        
          <li>
            <a
              class="gblog-nav__entry"
              href="/tags/LLM/"
            >
              Llm
            </a>
          </li>
        
      
        
          <li>
            <a
              class="gblog-nav__entry"
              href="/tags/thoughts/"
            >
              Thoughts
            </a>
          </li>
        
      
        
          <li>
            <a
              class="gblog-nav__entry"
              href="/tags/useful/"
            >
              Useful
            </a>
          </li>
        
      
    
    
  </ul>
</nav>



      <main class="gblog-page container">
        
  <article class="gblog-post">
    <header class="gblog-post__header">
      
      

      


      <h1 class="gblog-post__title">Lost in the Middle. Перевод знаменитой статьи</h1>

      
        <div class="flex flex-wrap align-center gblog-post__meta gblog-post__meta--head">
          <span class="flex align-center no-wrap gblog-post__meta--update">
  <svg class="gblog-icon gblog_date"><use xlink:href="#gblog_date"></use></svg>
  <span class="gblog-post__tag">
    <time datetime="2025-08-30T22:38:23&#43;03:00">
      
      Aug 30, 2025
    </time>
  </span>
</span>

<span class="flex align-center no-wrap gblog-post__meta--readtime">
  <svg class="gblog-icon gblog_timer"><use xlink:href="#gblog_timer"></use></svg>
  <span class="gblog-post__tag">13 min read</span>
</span>








  
    
    
      
        <span class="flex align-center no-wrap gblog-post__meta--tag">
          <svg class="gblog-icon gblog_bookmark"><use xlink:href="#gblog_bookmark"></use></svg>
          
  <span class="gblog-post__tag gblog-button gblog-button--regular">
    <a
      class="gblog-button__link"
      href="/tags/LLM/"
      title="All posts tagged with 'LLM'"
    >
      LLM
    </a>
  </span>

        </span>
      
    
    
  













        </div>
      
    </header>
    <section class="gblog-markdown">
      <p>Ниже представлен перевод знаменитой <a
  class="gblog-markdown__link"
  href="https://arxiv.org/abs/2307.03172"
>статьи Lost in the Middle</a> о том, что номинальная длина контекстного окна &ndash; это совсем не то же самое, что и эффективная.</p>
<p>Ссылки:</p>
<ul>
<li><a
  class="gblog-markdown__link"
  href="Lost_in_the_Middle-2307.03172v3-en.pdf"
>PDF оригинальной статьи</a></li>
<li><a
  class="gblog-markdown__link"
  href="Lost_in_the_Middle-2307.03172v3-ru.pdf"
>PDF перевода статьи</a></li>
<li>Источник: <a
  class="gblog-markdown__link"
  href="https://arxiv.org/abs/2307.03172"
>https://arxiv.org/abs/2307.03172</a></li>
</ul>
<div class="flex align-center gblog-post__anchorwrap">
    <h1 id="потерянные-в-середине-как-языковые-модели-используют-длинные-контексты"
    >
        Потерянные в середине: как языковые модели используют длинные контексты
    </h1>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#потерянные-в-середине-как-языковые-модели-используют-длинные-контексты" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Потерянные в середине: как языковые модели используют длинные контексты" href="#%d0%bf%d0%be%d1%82%d0%b5%d1%80%d1%8f%d0%bd%d0%bd%d1%8b%d0%b5-%d0%b2-%d1%81%d0%b5%d1%80%d0%b5%d0%b4%d0%b8%d0%bd%d0%b5-%d0%ba%d0%b0%d0%ba-%d1%8f%d0%b7%d1%8b%d0%ba%d0%be%d0%b2%d1%8b%d0%b5-%d0%bc%d0%be%d0%b4%d0%b5%d0%bb%d0%b8-%d0%b8%d1%81%d0%bf%d0%be%d0%bb%d1%8c%d0%b7%d1%83%d1%8e%d1%82-%d0%b4%d0%bb%d0%b8%d0%bd%d0%bd%d1%8b%d0%b5-%d0%ba%d0%be%d0%bd%d1%82%d0%b5%d0%ba%d1%81%d1%82%d1%8b">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p><em>Lost in the Middle: How Language Models Use Long Contexts</em></p>
<p><strong>Авторы:</strong><br>
Nelson F. Liu*, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, Percy Liang<br>
*Работа частично выполнена в качестве стажёра в Samaya AI.</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="аннотация"
    >
        Аннотация
    </h2>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#аннотация" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Аннотация" href="#%d0%b0%d0%bd%d0%bd%d0%be%d1%82%d0%b0%d1%86%d0%b8%d1%8f">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Хотя современные языковые модели могут принимать длинные контексты в качестве входных данных, относительно мало известно о том, насколько хорошо они <em>используют</em> более длинные контексты.<br>
Мы анализируем производительность языковых моделей в двух задачах, требующих идентификации релевантной информации в их входных контекстах: многодокументный вопросно-ответный анализ и извлечение ключевых значений.<br>
Мы обнаруживаем, что производительность может значительно ухудшаться при изменении позиции релевантной информации, что указывает на то, что текущие языковые модели не могут надежно использовать информацию в длинных входных контекстах.<br>
В частности, мы наблюдаем, что производительность часто максимальна, когда релевантная информация находится в начале или в конце входного контекста, и значительно ухудшается, когда модели должны получать доступ к релевантной информации в середине длинных контекстов, даже для моделей с явно длинным контекстом.<br>
Наш анализ дает лучшее понимание того, как языковые модели используют свой входной контекст, и предлагает новые протоколы оценки для будущих моделей с длинным контекстом.</p>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="введение"
    >
        Введение
    </h2>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#введение" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Введение" href="#%d0%b2%d0%b2%d0%b5%d0%b4%d0%b5%d0%bd%d0%b8%d0%b5">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p><img
  src="figures/figure1.png"
  alt="U-образная кривая производительности"
  
/>
<em>Изменение местоположения релевантной информации (позиции отрывка, который отвечает на входной вопрос) в контексте входных данных языковой модели приводит к U-образной кривой производительности — модели лучше используют релевантную информацию, которая находится в самом начале (эффект первичности) или в конце её входного контекста (эффект недавности), а производительность значительно ухудшается, когда модели должны получать доступ и использовать информацию, расположенную в середине её входного контекста.</em></p>
<p>Языковые модели стали важным и гибким строительным блоком в различных языковых технологиях, ориентированных на пользователя, включая разговорные интерфейсы, поиск и суммаризацию, а также совместное написание [Shuster et al., 2022; Thoppilan et al., 2022; Lee et al., 2022].<br>
Эти модели выполняют задачи нижнего уровня в основном через подсказки: вся релевантная спецификация задачи и данные для обработки форматируются как текстовый входной контекст, и модель возвращает сгенерированное текстовое завершение.<br>
Эти входные контексты могут содержать тысячи токенов, особенно когда языковые модели используются для обработки длинных документов (например, юридических или научных документов, истории разговоров и т. д.) или когда языковые модели дополняются внешней информацией (например, релевантными документами из поисковой системы, результатами запросов к базе данных и т. д.; [Petroni et al., 2020; Ram et al., 2023; Shi et al., 2023; Mallen et al., 2023; Schick et al., 2023]).</p>
<p>Обработка этих случаев использования требует, чтобы языковые модели успешно работали с длинными последовательностями.<br>
Существующие языковые модели обычно реализуются с помощью трансформеров [Vaswani et al., 2017], которые требуют памяти и вычислений, увеличивающихся квадратично в зависимости от длины последовательности.<br>
В результате трансформерные языковые модели часто обучались с относительно небольшими оконными контекстами (от 512 до 2048 токенов).<br>
Недавние улучшения в аппаратном обеспечении (например, более быстрые графические процессоры с большим объемом памяти) и алгоритмах [Dai et al., 2019; Dao et al., 2022; Poli et al., 2023; Rubin et al., 2023] привели к появлению языковых моделей с большими оконными контекстами (например, 4096, 32K и даже 100K токенов), но остается неясным, как эти модели с расширенным контекстом используют свои входные контексты при выполнении задач нижнего уровня.</p>
<p>Мы эмпирически исследуем этот вопрос с помощью контролируемых экспериментов с различными современными открытыми (MPT-30B-Instruct, LongChat-13B (16K)) и закрытыми (OpenAI&rsquo;s GPT-3.5-Turbo и Anthropic&rsquo;s Claude-1.3) языковыми моделями в условиях, требующих доступа и использования информации в пределах входного контекста.<br>
В частности, в наших экспериментах вносятся контролируемые изменения в размер входного контекста и положение релевантной информации в пределах входного контекста, и изучаются их эффекты на производительность языковой модели.<br>
Если языковые модели могут надежно использовать информацию в пределах длинных входных контекстов, то их производительность должна быть <em>минимально подвержена</em> влиянию положения релевантной информации в контексте входных данных.</p>
<p>Сначала мы экспериментируем с многодокументным вопросно-ответным анализом, который требует от моделей анализа предоставленных документов для нахождения релевантной информации и использования её для ответа на заданный вопрос; эта задача имитирует настройку генерации с дополнением поиска, лежащую в основе многих коммерческих приложений генеративного поиска и вопросно-ответного анализа (например, Bing Chat).<br>
В этом контексте мы контролируем (i)~длину входного контекста, изменяя количество документов в контексте входных данных (аналогично извлечению большего или меньшего количества документов в генерации с дополнением поиска), и (ii)~контролируем положение релевантной информации в пределах входного контекста, изменяя порядок документов, чтобы разместить релевантный документ в начале, середине или конце контекста.</p>
<p>Мы обнаруживаем, что изменение положения релевантной информации в контексте входных данных может существенно повлиять на производительность модели, что указывает на то, что текущие языковые модели не могут надежно получать доступ и использовать информацию в длинных входных контекстах.<br>
Более того, мы наблюдаем характерную U-образную кривую производительности (см. рисунок выше); производительность языковой модели наивысшая, когда релевантная информация находится в самом начале (эффект первичности) или в конце её входного контекста (эффект недавности), и производительность значительно ухудшается, когда модели должны получать доступ и использовать информацию в середине своих входных контекстов (§ QA Results).<br>
Например, когда релевантная информация размещена в середине её входного контекста, производительность GPT-3.5-Turbo на задаче многодокументного вопросно-ответного анализа ниже, чем её производительность при прогнозировании <em>без каких-либо документов</em> (т.е. в закрытой книге; 56.1%).<br>
Кроме того, мы обнаруживаем, что модели часто имеют идентичную производительность с их аналогами с расширенным контекстом, что указывает на то, что модели с расширенным контекстом не обязательно лучше используют свой входной контекст (§ QA Results).</p>
<p>Учитывая, что языковые модели испытывают трудности с извлечением и использованием релевантной информации в задаче многодокументного вопросно-ответного анализа, в какой степени языковые модели вообще могут <em>извлекать</em> из своих входных контекстов?<br>
Мы изучаем этот вопрос с помощью синтетической задачи извлечения ключевых значений, которая предназначена для минимального тестирования базовой способности извлекать совпадающие токены из входного контекста.<br>
В этой задаче моделям предоставляется коллекция пар ключ-значение в формате JSON, и они должны вернуть значение, связанное с определенным ключом.<br>
Подобно задаче многодокументного вопросно-ответного анализа, задача извлечения ключевых значений допускает контролируемые изменения длины входного контекста (добавление большего количества пар ключ-значение) и положения релевантной информации.<br>
Хотя некоторые модели выполняют синтетическую задачу извлечения ключевых значений идеально, другие модели испытывают трудности даже с простым извлечением совпадающих токенов, которые встречаются в середине их входного контекста, и продолжают демонстрировать U-образную кривую производительности.</p>
<p>Чтобы лучше понять, почему языковые модели испытывают трудности с надежным доступом и использованием информации в своих входных контекстах, мы изучаем роль архитектуры модели (только декодер против кодер-декодер), контекстуализации с учетом запроса и тонкой настройки инструкций (§ Why U-shape). Мы обнаруживаем, что:</p>
<ul>
<li>Кодер-декодер модели относительно устойчивы к изменениям положения релевантной информации в их входном контексте, но только при оценке последовательностей в пределах их максимальной длины последовательности на этапе обучения. При оценке последовательностей, превышающих те, что были видны во время обучения, мы наблюдаем U-образную кривую производительности (§ Architecture).</li>
<li>Контекстуализация с учетом запроса (размещение запроса перед <em>и</em> после документов или пар ключ-значение) обеспечивает почти идеальную производительность в синтетической задаче извлечения ключевых значений, но минимально изменяет тенденции в многодокументном вопросно-ответном анализе (§ Pre-conditioning).</li>
<li>Даже базовые языковые модели (т.е. без тонкой настройки инструкций) демонстрируют U-образную кривую производительности при изменении положения релевантной информации в контексте входных данных.</li>
</ul>
<p>Наши результаты показывают, что предоставление языковым моделям более длинных входных контекстов — это компромисс: предоставление языковой модели большего объема информации может помочь ей выполнить задачу нижнего уровня, но также увеличивает объем контента, который модель должна анализировать, что может снизить точность.<br>
Чтобы лучше понять этот компромисс на практике, мы проводим тематическое исследование с моделями извлечения-читателя на открытом вопросно-ответном анализе (§ ODQA Case Study).<br>
В отличие от нашей контролируемой задачи многодокументного вопросно-ответного анализа, где контекст всегда содержит ровно <em>один</em> документ, который отвечает на вопрос, ни один или многие из топ $k$ документов могут не содержать ответа в настройке открытого вопросно-ответного анализа.<br>
Когда мы извлекаем из Википедии, чтобы ответить на запросы из NaturalQuestions-Open, мы обнаруживаем, что производительность модели насыщается задолго до насыщения извлечения, что указывает на то, что текущие модели не могут эффективно использовать дополнительные извлеченные документы — использование 50 документов вместо 20 извлеченных документов лишь незначительно улучшает производительность ($\sim$1.5% для GPT-3.5-Turbo и $\sim$1% для Claude-1.3).</p>
<p>Наш анализ дает лучшее понимание того, как языковые модели используют свой входной контекст, и вводит новые протоколы оценки для будущих моделей с длинным контекстом; чтобы утверждать, что языковая модель может надежно использовать информацию в пределах длинных входных контекстов, необходимо показать, что её производительность минимально подвержена влиянию положения релевантной информации в контексте входных данных (например, минимальная разница в наилучшей и наихудшей производительности).<br>
Чтобы способствовать дальнейшей работе по пониманию и улучшению того, как языковые модели используют свой входной контекст, мы выпускаем наш код и данные оценки.<br>
<a
  class="gblog-markdown__link"
  href="https://nelsonliu.me/papers/lost-in-the-middle"
>https://nelsonliu.me/papers/lost-in-the-middle</a></p>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="многодокументный-вопросно-ответный-анализ"
    >
        Многодокументный вопросно-ответный анализ
    </h2>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#многодокументный-вопросно-ответный-анализ" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Многодокументный вопросно-ответный анализ" href="#%d0%bc%d0%bd%d0%be%d0%b3%d0%be%d0%b4%d0%be%d0%ba%d1%83%d0%bc%d0%b5%d0%bd%d1%82%d0%bd%d1%8b%d0%b9-%d0%b2%d0%be%d0%bf%d1%80%d0%be%d1%81%d0%bd%d0%be-%d0%be%d1%82%d0%b2%d0%b5%d1%82%d0%bd%d1%8b%d0%b9-%d0%b0%d0%bd%d0%b0%d0%bb%d0%b8%d0%b7">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="экспериментальная-установка"
    >
        Экспериментальная установка
    </h3>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#экспериментальная-установка" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Экспериментальная установка" href="#%d1%8d%d0%ba%d1%81%d0%bf%d0%b5%d1%80%d0%b8%d0%bc%d0%b5%d0%bd%d1%82%d0%b0%d0%bb%d1%8c%d0%bd%d0%b0%d1%8f-%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>В задаче многодокументного вопросно-ответного анализа входные данные модели включают (i)<del>вопрос, на который нужно ответить, и (ii)</del>$k$ документов (например, отрывки из Википедии), где <em>ровно один</em> из документов содержит ответ на вопрос, а $k - 1$ «отвлекающих» документов не содержат.<br>
Эта задача требует от модели доступа к документу, содержащему ответ, в пределах её входного контекста и использования его для ответа на вопрос.</p>
<!-- ![Пример задачи многодокументного вопросно-ответного анализа](figures/qa_example.png) -->
<div class="flex align-center gblog-post__anchorwrap">
    <h4 id="пример-задачи-многодокументного-вопросно-ответного-анализа"
    >
        Пример задачи многодокументного вопросно-ответного анализа
    </h4>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#пример-задачи-многодокументного-вопросно-ответного-анализа" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Пример задачи многодокументного вопросно-ответного анализа" href="#%d0%bf%d1%80%d0%b8%d0%bc%d0%b5%d1%80-%d0%b7%d0%b0%d0%b4%d0%b0%d1%87%d0%b8-%d0%bc%d0%bd%d0%be%d0%b3%d0%be%d0%b4%d0%be%d0%ba%d1%83%d0%bc%d0%b5%d0%bd%d1%82%d0%bd%d0%be%d0%b3%d0%be-%d0%b2%d0%be%d0%bf%d1%80%d0%be%d1%81%d0%bd%d0%be-%d0%be%d1%82%d0%b2%d0%b5%d1%82%d0%bd%d0%be%d0%b3%d0%be-%d0%b0%d0%bd%d0%b0%d0%bb%d0%b8%d0%b7%d0%b0">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p><strong>Input Context</strong></p>
<blockquote>
<p>Write a high-quality answer for the given question using only the provided search results (some of which might be irrelevant).</p>
<p>Document [1](Title: Asian Americans in science and technology) Prize in physics for discovery of the subatomic particle J/ψ. Subrahmanyan Chandrasekhar shared&hellip;</p>
<p><strong>Document [2](Title: List of Nobel laureates in Physics) The first Nobel Prize in Physics was awarded in 1901 to Wilhelm Conrad Röntgen, of Germany, who received&hellip;</strong></p>
<p>Document [3](Title: Scientist) and pursued through a unique method, was essentially in place. Ramón y Cajal won the Nobel Prize in 1906 for his remarkable&hellip;</p>
<p>Question: who got the first nobel prize in physics <br>
Answer:</p>
</blockquote>
<p><strong>Desired Answer</strong></p>
<blockquote>
<p>Wilhelm Conrad Röntgen</p>
</blockquote>
<p><em>Документ, содержащий ответ, выделен для ясности.</em></p>
<p>Мы реализуем эту задачу с данными из NaturalQuestions-Open [Lee et al., 2019; Kwiatkowski et al., 2019], которые содержат исторические запросы, отправленные в поисковую систему Google, в сочетании с аннотированными людьми ответами, извлеченными из Википедии.<br>
В частности, мы берем 2655 запросов, где аннотированный длинный ответ является абзацем (в отличие от списка или таблицы).<br>
Мы используем отрывки (кусочки не более 100 токенов) из Википедии в качестве документов в пределах наших входных контекстов.<br>
Для каждого из запросов нам нужен документ, содержащий ответ, и $k-1$ отвлекающих документов, которые не содержат ответа.<br>
Чтобы получить документ, который отвечает на вопрос, мы используем абзац Википедии, содержащий ответ из аннотаций NaturalQuestions.</p>
<p>Чтобы собрать $k-1$ отвлекающих документов, которые не содержат ответа, мы используем систему извлечения (Contriever, дообученную на MS-MARCO; [Izacard et al., 2021]) для извлечения $k-1$ отрывков из Википедии, которые наиболее релевантны запросу и не содержат ни одного из аннотированных ответов NaturalQuestions.</p>
<p>Чтобы модулировать положение релевантной информации в пределах входного контекста, мы изменяем порядок документов, чтобы изменить положение документа, содержащего ответ.</p>
<!-- ![Модуляция положения релевантной информации](figures/qa_changing_position.png) -->
<div class="flex align-center gblog-post__anchorwrap">
    <h4 id="модуляция-положения-релевантной-информации"
    >
        Модуляция положения релевантной информации
    </h4>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#модуляция-положения-релевантной-информации" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Модуляция положения релевантной информации" href="#%d0%bc%d0%be%d0%b4%d1%83%d0%bb%d1%8f%d1%86%d0%b8%d1%8f-%d0%bf%d0%be%d0%bb%d0%be%d0%b6%d0%b5%d0%bd%d0%b8%d1%8f-%d1%80%d0%b5%d0%bb%d0%b5%d0%b2%d0%b0%d0%bd%d1%82%d0%bd%d0%be%d0%b9-%d0%b8%d0%bd%d1%84%d0%be%d1%80%d0%bc%d0%b0%d1%86%d0%b8%d0%b8">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p><strong>Input Context</strong></p>
<blockquote>
<p>Write a high-quality answer for the given question using only the provided search results (some of which might be irrelevant).</p>
<p><strong>Document [1](Title: List of Nobel laureates in Physics) &hellip;</strong> <br>
Document [2](Title: Asian Americans in science and technology) &hellip; <br>
Document [3](Title: Scientist) &hellip;</p>
<p>Question: who got the first nobel prize in physics <br>
Answer:</p>
</blockquote>
<p><strong>Desired Answer</strong></p>
<blockquote>
<p>Wilhelm Conrad Röntgen</p>
</blockquote>
<p>Чтобы модулировать длину входного контекста в этой задаче, мы увеличиваем или уменьшаем количество извлеченных документов, не содержащих ответа.</p>
<!-- ![Модуляция длины входного контекста](figures/qa_changing_length.png) -->
<div class="flex align-center gblog-post__anchorwrap">
    <h4 id="модуляция-длины-входного-контекста"
    >
        Модуляция длины входного контекста
    </h4>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#модуляция-длины-входного-контекста" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Модуляция длины входного контекста" href="#%d0%bc%d0%be%d0%b4%d1%83%d0%bb%d1%8f%d1%86%d0%b8%d1%8f-%d0%b4%d0%bb%d0%b8%d0%bd%d1%8b-%d0%b2%d1%85%d0%be%d0%b4%d0%bd%d0%be%d0%b3%d0%be-%d0%ba%d0%be%d0%bd%d1%82%d0%b5%d0%ba%d1%81%d1%82%d0%b0">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p><strong>Input Context</strong></p>
<blockquote>
<p>Write a high-quality answer for the given question using only the provided search results (some of which might be irrelevant).</p>
<p>Document [1](Title: Asian Americans in science and technology) &hellip; <br>
<strong>Document [2](Title: List of Nobel laureates in Physics) &hellip;</strong> <br>
Document [3](Title: Scientist) &hellip; <br>
Document [4](Title: Norwegian Americans) &hellip; <br>
Document [5](Title: Maria Goeppert Mayer) &hellip;</p>
<p>Question: who got the first nobel prize in physics <br>
Answer:</p>
</blockquote>
<p><strong>Desired Answer</strong></p>
<blockquote>
<p>Wilhelm Conrad Röntgen</p>
</blockquote>
<p>Следуя [Kandpal et al., 2022; Mallen et al., 2023], мы используем точность в качестве нашего основного показателя оценки, оценивая, появляется ли какой-либо из правильных ответов (как взято из аннотаций NaturalQuestions) в предсказанном выводе.</p>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="модели"
    >
        Модели
    </h3>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#модели" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Модели" href="#%d0%bc%d0%be%d0%b4%d0%b5%d0%bb%d0%b8">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Мы анализируем несколько современных открытых и закрытых языковых моделей.<br>
Мы используем жадное декодирование при генерации выводов и оставляем изучение других методов декодирования для будущей работы.<br>
Мы используем стандартный набор подсказок для каждой модели.</p>
<p><strong>Открытые модели:</strong></p>
<ul>
<li>MPT-30B-Instruct (максимальная длина контекста 8192 токена, ALiBi позиционирование)</li>
<li>LongChat-13B (16K) (расширенное окно контекста LLaMA-13B до 16384 токенов)</li>
</ul>
<p><strong>Закрытые модели:</strong></p>
<ul>
<li>GPT-3.5-Turbo (4K токенов) и GPT-3.5-Turbo (16K)</li>
<li>Claude-1.3 (8K токенов) и Claude-1.3 (100K токенов)</li>
<li>GPT-4 (8K) — только подмножество экспериментов</li>
</ul>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="результаты-и-обсуждение"
    >
        Результаты и обсуждение
    </h3>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#результаты-и-обсуждение" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Результаты и обсуждение" href="#%d1%80%d0%b5%d0%b7%d1%83%d0%bb%d1%8c%d1%82%d0%b0%d1%82%d1%8b-%d0%b8-%d0%be%d0%b1%d1%81%d1%83%d0%b6%d0%b4%d0%b5%d0%bd%d0%b8%d0%b5">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Мы экспериментируем с входными контекстами, содержащими 10, 20 и 30 документов.<br>
Ниже — производительность многодокументного вопросно-ответного анализа при изменении положения релевантной информации в пределах входного контекста.</p>
<p><img
  src="figures/qa.png"
  alt="Влияние положения релевантной информации"
  
/></p>
<div class="flex align-center gblog-post__anchorwrap">
    <h4 id="таблица-точность-языковых-моделей-в-закрытой-книге-и-оракульской-настройке"
    >
        Таблица: Точность языковых моделей в закрытой книге и оракульской настройке
    </h4>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#таблица-точность-языковых-моделей-в-закрытой-книге-и-оракульской-настройке" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Таблица: Точность языковых моделей в закрытой книге и оракульской настройке" href="#%d1%82%d0%b0%d0%b1%d0%bb%d0%b8%d1%86%d0%b0-%d1%82%d0%be%d1%87%d0%bd%d0%be%d1%81%d1%82%d1%8c-%d1%8f%d0%b7%d1%8b%d0%ba%d0%be%d0%b2%d1%8b%d1%85-%d0%bc%d0%be%d0%b4%d0%b5%d0%bb%d0%b5%d0%b9-%d0%b2-%d0%b7%d0%b0%d0%ba%d1%80%d1%8b%d1%82%d0%be%d0%b9-%d0%ba%d0%bd%d0%b8%d0%b3%d0%b5-%d0%b8-%d0%be%d1%80%d0%b0%d0%ba%d1%83%d0%bb%d1%8c%d1%81%d0%ba%d0%be%d0%b9-%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%be%d0%b9%d0%ba%d0%b5">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<div class=table-wrap> <table>
  <thead>
      <tr>
          <th>Модель</th>
          <th style="text-align: center">Закрытая книга</th>
          <th style="text-align: center">Оракул</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>LongChat-13B (16K)</td>
          <td style="text-align: center">35.0%</td>
          <td style="text-align: center">83.4%</td>
      </tr>
      <tr>
          <td>MPT-30B-Instruct</td>
          <td style="text-align: center">31.5%</td>
          <td style="text-align: center">81.9%</td>
      </tr>
      <tr>
          <td>GPT-3.5-Turbo</td>
          <td style="text-align: center">56.1%</td>
          <td style="text-align: center">88.3%</td>
      </tr>
      <tr>
          <td>GPT-3.5-Turbo (16K)</td>
          <td style="text-align: center">56.0%</td>
          <td style="text-align: center">88.6%</td>
      </tr>
      <tr>
          <td>Claude-1.3</td>
          <td style="text-align: center">48.3%</td>
          <td style="text-align: center">76.1%</td>
      </tr>
      <tr>
          <td>Claude-1.3 (100K)</td>
          <td style="text-align: center">48.2%</td>
          <td style="text-align: center">76.4%</td>
      </tr>
  </tbody>
</table> </div>
<div class="flex align-center gblog-post__anchorwrap">
    <h4 id="основные-выводы"
    >
        Основные выводы
    </h4>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#основные-выводы" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Основные выводы" href="#%d0%be%d1%81%d0%bd%d0%be%d0%b2%d0%bd%d1%8b%d0%b5-%d0%b2%d1%8b%d0%b2%d0%be%d0%b4%d1%8b">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<ul>
<li><strong>Производительность максимальна, когда релевантная информация в начале или конце контекста.</strong><br>
U-образная кривая производительности: модели лучше используют релевантную информацию, находящуюся в начале (эффект первичности) или в конце (эффект недавности) контекста, и производительность значительно ухудшается, когда информация в середине.</li>
<li><strong>Модели с расширенным контекстом не обязательно лучше используют входной контекст.</strong><br>
Производительность между обычной и расширенной версией модели почти идентична, если входной контекст помещается в их окно.</li>
</ul>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="насколько-хорошо-языковые-модели-могут-извлекать-из-входных-контекстов"
    >
        Насколько хорошо языковые модели могут извлекать из входных контекстов?
    </h2>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#насколько-хорошо-языковые-модели-могут-извлекать-из-входных-контекстов" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Насколько хорошо языковые модели могут извлекать из входных контекстов?" href="#%d0%bd%d0%b0%d1%81%d0%ba%d0%be%d0%bb%d1%8c%d0%ba%d0%be-%d1%85%d0%be%d1%80%d0%be%d1%88%d0%be-%d1%8f%d0%b7%d1%8b%d0%ba%d0%be%d0%b2%d1%8b%d0%b5-%d0%bc%d0%be%d0%b4%d0%b5%d0%bb%d0%b8-%d0%bc%d0%be%d0%b3%d1%83%d1%82-%d0%b8%d0%b7%d0%b2%d0%bb%d0%b5%d0%ba%d0%b0%d1%82%d1%8c-%d0%b8%d0%b7-%d0%b2%d1%85%d0%be%d0%b4%d0%bd%d1%8b%d1%85-%d0%ba%d0%be%d0%bd%d1%82%d0%b5%d0%ba%d1%81%d1%82%d0%be%d0%b2">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Учитывая, что языковые модели испытывают трудности с извлечением и использованием информации из середины их входных контекстов в задаче многодокументного вопросно-ответного анализа, в какой степени они могут просто <em>извлекать</em> из входных контекстов?<br>
Мы изучаем этот вопрос с помощью синтетической задачи извлечения ключевых значений.</p>
<!-- ![Пример задачи извлечения ключевых значений](figures/kv_retrieval_example.png) -->
<p><strong>Input Context</strong></p>
<blockquote>
<p>Extract the value corresponding to the specified key in the JSON object below.</p>
<p>JSON data:</p>
</blockquote>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-json" data-lang="json"><span class="line"><span class="cl"><span class="p">{</span><span class="nt">&#34;2a8d601d-1d69-4e64-9f90-8ad825a74195&#34;</span><span class="p">:</span> <span class="s2">&#34;bb3ba2a5-7de8-434b-a86e-a88bb9fa7289&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="nt">&#34;a54e2eed-e625-4570-9f74-3624e77d6684&#34;</span><span class="p">:</span> <span class="s2">&#34;d1ff29be-4e2a-4208-a182-0cea716be3d4&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="nt">&#34;9f4a92b9-5f69-4725-ba1e-403f08dea695&#34;</span><span class="p">:</span> <span class="s2">&#34;703a7ce5-f17f-4e6d-b895-5836ba5ec71c&#34;</span><span class="p">,</span> <span class="c1">// &lt;--
</span></span></span><span class="line"><span class="cl"><span class="c1"></span> <span class="nt">&#34;52a9c80c-da51-4fc9-bf70-4a4901bc2ac3&#34;</span><span class="p">:</span> <span class="s2">&#34;b2f8ea3d-4b1b-49e0-a141-b9823991ebeb&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="nt">&#34;f4eb1c53-af0a-4dc4-a3a5-c2d50851a178&#34;</span><span class="p">:</span> <span class="s2">&#34;d733b0d2-6af3-44e1-8592-e5637fdb76fb&#34;</span><span class="p">}</span>
</span></span></code></pre></div><blockquote>
<p>Key: &ldquo;<strong>9f4a92b9-5f69-4725-ba1e-403f08dea695</strong>&rdquo;
Corresponding value:</p>
</blockquote>
<p><strong>Desired Output</strong></p>
<blockquote>
<p>703a7ce5-f17f-4e6d-b895-5836ba5ec71c</p>
</blockquote>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="экспериментальная-установка-1"
    >
        Экспериментальная установка
    </h3>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#экспериментальная-установка-1" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Экспериментальная установка" href="#%d1%8d%d0%ba%d1%81%d0%bf%d0%b5%d1%80%d0%b8%d0%bc%d0%b5%d0%bd%d1%82%d0%b0%d0%bb%d1%8c%d0%bd%d0%b0%d1%8f-%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0-1">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Входные данные включают:</p>
<ul>
<li>сериализованный объект JSON с $k$ парами ключ-значение (UUID)</li>
<li>ключ, для которого нужно вернуть значение</li>
</ul>
<p>Мы измеряем точность, оценивая, появляется ли правильное значение в предсказанном выводе.</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="результаты"
    >
        Результаты
    </h3>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#результаты" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Результаты" href="#%d1%80%d0%b5%d0%b7%d1%83%d0%bb%d1%8c%d1%82%d0%b0%d1%82%d1%8b">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p><img
  src="figures/kv_records.png"
  alt="Влияние длины и положения релевантной информации"
  
/></p>
<ul>
<li>Claude-1.3 и Claude-1.3 (100K) почти идеально выполняют задачу на всех длинах контекста.</li>
<li>GPT-3.5-Turbo, GPT-3.5-Turbo (16K) и MPT-30B-Instruct испытывают трудности, особенно при большом количестве пар.</li>
<li>U-образная кривая производительности сохраняется: наименьшая точность — при необходимости извлекать из середины контекста.</li>
</ul>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="почему-языковые-модели-не-устойчивы-к-изменениям-положения-релевантной-информации"
    >
        Почему языковые модели не устойчивы к изменениям положения релевантной информации?
    </h2>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#почему-языковые-модели-не-устойчивы-к-изменениям-положения-релевантной-информации" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Почему языковые модели не устойчивы к изменениям положения релевантной информации?" href="#%d0%bf%d0%be%d1%87%d0%b5%d0%bc%d1%83-%d1%8f%d0%b7%d1%8b%d0%ba%d0%be%d0%b2%d1%8b%d0%b5-%d0%bc%d0%be%d0%b4%d0%b5%d0%bb%d0%b8-%d0%bd%d0%b5-%d1%83%d1%81%d1%82%d0%be%d0%b9%d1%87%d0%b8%d0%b2%d1%8b-%d0%ba-%d0%b8%d0%b7%d0%bc%d0%b5%d0%bd%d0%b5%d0%bd%d0%b8%d1%8f%d0%bc-%d0%bf%d0%be%d0%bb%d0%be%d0%b6%d0%b5%d0%bd%d0%b8%d1%8f-%d1%80%d0%b5%d0%bb%d0%b5%d0%b2%d0%b0%d0%bd%d1%82%d0%bd%d0%be%d0%b9-%d0%b8%d0%bd%d1%84%d0%be%d1%80%d0%bc%d0%b0%d1%86%d0%b8%d0%b8">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Мы исследуем роль архитектуры модели, контекстуализации с учетом запроса и тонкой настройки инструкций.</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="влияние-архитектуры-модели"
    >
        Влияние архитектуры модели
    </h3>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#влияние-архитектуры-модели" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Влияние архитектуры модели" href="#%d0%b2%d0%bb%d0%b8%d1%8f%d0%bd%d0%b8%d0%b5-%d0%b0%d1%80%d1%85%d0%b8%d1%82%d0%b5%d0%ba%d1%82%d1%83%d1%80%d1%8b-%d0%bc%d0%be%d0%b4%d0%b5%d0%bb%d0%b8">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p><img
  src="figures/qa_decoder_only_vs_encoder_decoder.png"
  alt="Сравнение моделей только-декодера и кодер-декодер"
  
/></p>
<ul>
<li>Кодер-декодер модели (Flan-UL2, Flan-T5-XXL) устойчивы к изменению позиции релевантной информации, если длина последовательности не превышает ту, что была на обучении.</li>
<li>При более длинных последовательностях появляется U-образная кривая.</li>
</ul>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="влияние-контекстуализации-с-учетом-запроса"
    >
        Влияние контекстуализации с учетом запроса
    </h3>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#влияние-контекстуализации-с-учетом-запроса" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Влияние контекстуализации с учетом запроса" href="#%d0%b2%d0%bb%d0%b8%d1%8f%d0%bd%d0%b8%d0%b5-%d0%ba%d0%be%d0%bd%d1%82%d0%b5%d0%ba%d1%81%d1%82%d1%83%d0%b0%d0%bb%d0%b8%d0%b7%d0%b0%d1%86%d0%b8%d0%b8-%d1%81-%d1%83%d1%87%d0%b5%d1%82%d0%be%d0%bc-%d0%b7%d0%b0%d0%bf%d1%80%d0%be%d1%81%d0%b0">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p><img
  src="figures/20_total_documents_precondition_with_question.jpg"
  alt="Контекстуализация с учетом запроса"
  
/></p>
<ul>
<li>Размещение запроса перед <em>и</em> после данных почти не влияет на тенденции в многодокументном вопросно-ответном анализе, но помогает в синтетической задаче извлечения ключевых значений.</li>
</ul>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="влияние-тонкой-настройки-инструкций"
    >
        Влияние тонкой настройки инструкций
    </h3>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#влияние-тонкой-настройки-инструкций" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Влияние тонкой настройки инструкций" href="#%d0%b2%d0%bb%d0%b8%d1%8f%d0%bd%d0%b8%d0%b5-%d1%82%d0%be%d0%bd%d0%ba%d0%be%d0%b9-%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%be%d0%b9%d0%ba%d0%b8-%d0%b8%d0%bd%d1%81%d1%82%d1%80%d1%83%d0%ba%d1%86%d0%b8%d0%b9">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p><img
  src="figures/base_vs_instruction_tuned.jpg"
  alt="Базовая модель vs. после тонкой настройки инструкций"
  
/></p>
<ul>
<li>U-образная кривая наблюдается как у базовой модели, так и у модели после тонкой настройки инструкций.</li>
<li>Тонкая настройка инструкций слегка уменьшает разницу между наилучшей и наихудшей производительностью.</li>
</ul>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="всегда-ли-больше-контекста-лучше-тематическое-исследование-с-открытым-вопросно-ответным-анализом"
    >
        Всегда ли больше контекста лучше? Тематическое исследование с открытым вопросно-ответным анализом
    </h2>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#всегда-ли-больше-контекста-лучше-тематическое-исследование-с-открытым-вопросно-ответным-анализом" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Всегда ли больше контекста лучше? Тематическое исследование с открытым вопросно-ответным анализом" href="#%d0%b2%d1%81%d0%b5%d0%b3%d0%b4%d0%b0-%d0%bb%d0%b8-%d0%b1%d0%be%d0%bb%d1%8c%d1%88%d0%b5-%d0%ba%d0%be%d0%bd%d1%82%d0%b5%d0%ba%d1%81%d1%82%d0%b0-%d0%bb%d1%83%d1%87%d1%88%d0%b5-%d1%82%d0%b5%d0%bc%d0%b0%d1%82%d0%b8%d1%87%d0%b5%d1%81%d0%ba%d0%be%d0%b5-%d0%b8%d1%81%d1%81%d0%bb%d0%b5%d0%b4%d0%be%d0%b2%d0%b0%d0%bd%d0%b8%d0%b5-%d1%81-%d0%be%d1%82%d0%ba%d1%80%d1%8b%d1%82%d1%8b%d0%bc-%d0%b2%d0%be%d0%bf%d1%80%d0%be%d1%81%d0%bd%d0%be-%d0%be%d1%82%d0%b2%d0%b5%d1%82%d0%bd%d1%8b%d0%bc-%d0%b0%d0%bd%d0%b0%d0%bb%d0%b8%d0%b7%d0%be%d0%bc">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<ul>
<li>Предоставление языковой модели большего объема информации может помочь, но также увеличивает объем контента для анализа, что может снизить точность.</li>
<li>В экспериментах с NaturalQuestions-Open производительность модели насыщается задолго до насыщения извлечения: использование 50 документов вместо 20 улучшает точность лишь на 1–1.5%.</li>
</ul>
<p><img
  src="figures/odqa.jpg"
  alt="Извлечение и производительность модели в зависимости от количества документов"
  
/></p>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="связанные-работы"
    >
        Связанные работы
    </h2>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#связанные-работы" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Связанные работы" href="#%d1%81%d0%b2%d1%8f%d0%b7%d0%b0%d0%bd%d0%bd%d1%8b%d0%b5-%d1%80%d0%b0%d0%b1%d0%be%d1%82%d1%8b">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="языковые-модели-с-длинным-контекстом"
    >
        Языковые модели с длинным контекстом
    </h3>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#языковые-модели-с-длинным-контекстом" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Языковые модели с длинным контекстом" href="#%d1%8f%d0%b7%d1%8b%d0%ba%d0%be%d0%b2%d1%8b%d0%b5-%d0%bc%d0%be%d0%b4%d0%b5%d0%bb%d0%b8-%d1%81-%d0%b4%d0%bb%d0%b8%d0%bd%d0%bd%d1%8b%d0%bc-%d0%ba%d0%be%d0%bd%d1%82%d0%b5%d0%ba%d1%81%d1%82%d0%be%d0%bc">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Много работ посвящено масштабированию трансформеров по длине контекста: модификации внимания (рекуррентность, аппроксимации, свертки, линейные RNN), ускоренные реализации (FlashAttention), отказ от внимания (RWKV, S4, Hyena).<br>
Оценка часто проводится по перплексии, но точный доступ к знаниям на длинных контекстах — отдельная задача.</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="как-языковые-модели-используют-контекст"
    >
        Как языковые модели используют контекст?
    </h3>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#как-языковые-модели-используют-контекст" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Как языковые модели используют контекст?" href="#%d0%ba%d0%b0%d0%ba-%d1%8f%d0%b7%d1%8b%d0%ba%d0%be%d0%b2%d1%8b%d0%b5-%d0%bc%d0%be%d0%b4%d0%b5%d0%bb%d0%b8-%d0%b8%d1%81%d0%bf%d0%be%d0%bb%d1%8c%d0%b7%d1%83%d1%8e%d1%82-%d0%ba%d0%be%d0%bd%d1%82%d0%b5%d0%ba%d1%81%d1%82">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Ранние работы показали, что LSTM используют долгосрочный контекст все менее эффективно; внимательные LSTM склонны к недавности; трансформеры часто не используют долгосрочный контекст эффективно; длинный контекст помогает только для некоторых токенов.</p>
<div class="flex align-center gblog-post__anchorwrap">
    <h3 id="эффект-серийной-позиции"
    >
        Эффект серийной позиции
    </h3>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#эффект-серийной-позиции" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Эффект серийной позиции" href="#%d1%8d%d1%84%d1%84%d0%b5%d0%ba%d1%82-%d1%81%d0%b5%d1%80%d0%b8%d0%b9%d0%bd%d0%be%d0%b9-%d0%bf%d0%be%d0%b7%d0%b8%d1%86%d0%b8%d0%b8">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>U-образная кривая соответствует эффекту серийной позиции в психологии: люди лучше запоминают первые и последние элементы списка.<br>
В трансформерах, несмотря на техническую возможность извлекать любой токен, наблюдается аналогичный эффект.</p>
<hr>
<div class="flex align-center gblog-post__anchorwrap">
    <h2 id="заключение"
    >
        Заключение
    </h2>
    <a data-clipboard-text="https://valmat.ru/posts/2025/08/lost-in-the-middle/#заключение" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Заключение" href="#%d0%b7%d0%b0%d0%ba%d0%bb%d1%8e%d1%87%d0%b5%d0%bd%d0%b8%d0%b5">
        <svg class="gblog-icon gblog_link"><use xlink:href="#gblog_link"></use></svg>
    </a>
</div>
<p>Мы эмпирически изучаем, как языковые модели используют длинные входные контексты.<br>
Показываем, что производительность моделей значительно ухудшается при изменении положения релевантной информации — особенно в середине длинных контекстов.<br>
Проводим исследование роли архитектуры, контекстуализации с учетом запроса и тонкой настройки инструкций.<br>
В тематическом исследовании ODQA обнаруживаем, что производительность насыщается задолго до насыщения извлечения.<br>
Наши результаты дают лучшее понимание того, как языковые модели используют контекст, и предлагают новые протоколы оценки для будущих моделей с длинным контекстом.</p>

    </section>
  </article>

      </main>

      <footer class="gblog-footer">
  <nav class="container flex">
    <div>
      <section class="flex flex-wrap align-center">
        
          <span class="gblog-footer__item gblog-footer__item--row">
            <svg class="gblog-icon gblog_rss_feed"><use xlink:href="#gblog_rss_feed"></use></svg>
            <a href="/feed.xml" class="gblog-footer__link">Atom Feed</a>
          </span>
        
        
        
        
      </section>
      <section class="flex flex-wrap align-center">
        
      </section>
      
      
    </div>
    
      <div class="flex flex-25 justify-end">
        <span class="gblog-footer__item text-right">
          <a class="gblog-footer__link fake-link" href="#" aria-label="Back to top">
            <svg class="gblog-icon gblog_keyboard_arrow_up">
              <use xlink:href="#gblog_keyboard_arrow_up"></use>
            </svg>
            <span class="hidden-mobile">Back to top</span>
          </a>
        </span>
      </div>
    
  </nav>
</footer>

    </div>
  </body>
</html>
